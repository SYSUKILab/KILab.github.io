[{"content":" Welcome to the Knowledge Intelligence Lab (KILab) !\nOur lab is directed by Dr. Ziyu Lyu. We are dedicated to advancing cutting-edge research in Knowledge Intelligence. We are specified in Secure and Trusted AI, Intelligent Information Retrieval, Natural Language Processing. Recently, we are focusing on AIGC Safety, Social Media Content Safety and Reliable Recommender System.\nWe are actively recruiting Postdocs, PhD students, Master students,and research interns. Welcome to Join us!\nFeatured Projects # ğŸ”¬ Computer Vision D-Judge A Large-Scale Dataset for Visual Research on AI-Synthesized and Natural Images\nğŸ“„ arXiv ğŸ¤— Dataset ğŸ’» GitHub âš¡ AI Safety MidPO Dual Preference Optimization for Safety and Helpfulness in LLMs via MoE Framework\nğŸ“„ arXiv ğŸ’» Code (Soon) âš–ï¸ Fairness FairWork Fairness-aware Work Allocation and Assessment Demo\nğŸ® Demo [2025.8] Congrats to Pengyu Qi! Our work, \u0026ldquo;MidPO: Dual Preference Optimization for Safety and Helpfulness in LLMs via MoE Framework\u0026rdquo;, has been accepted by EMNLP FINDING 2025. [2025.7] Congrats to Renyang Liu! Our collaborative work, \u0026ldquo;D-Judge: How Far Are We? Accessing the Discrepancies Between AI-synthesized Images and Natural Images through Multimodal Guidance\u0026rdquo;, has been accepted by ACM MM 2025. ","date":null,"permalink":"http://localhost:1313/","section":"","summary":"\u003cdiv class=\"flex rounded-md bg-primary-100 px-4 py-3 dark:bg-primary-900\"\u003e\n  \u003cspan class=\"pe-3 text-primary-400\"\u003e\n    \u003cspan class=\"icon relative inline-block px-1 align-text-bottom\"\u003e\u003csvg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 512 512\"\u003e\u003cpath fill=\"currentColor\" d=\"M256 0C114.6 0 0 114.6 0 256s114.6 256 256 256s256-114.6 256-256S397.4 0 256 0zM256 128c17.67 0 32 14.33 32 32c0 17.67-14.33 32-32 32S224 177.7 224 160C224 142.3 238.3 128 256 128zM296 384h-80C202.8 384 192 373.3 192 360s10.75-24 24-24h16v-64H224c-13.25 0-24-10.75-24-24S210.8 224 224 224h32c13.25 0 24 10.75 24 24v88h16c13.25 0 24 10.75 24 24S309.3 384 296 384z\"/\u003e\u003c/svg\u003e\n\u003c/span\u003e\n  \u003c/span\u003e\n  \u003cspan class=\"dark:text-neutral-300\"\u003e\u003cp\u003e\u003cstrong\u003eWelcome to the Knowledge Intelligence Lab (KILab) !\u003c/strong\u003e\u003c/p\u003e","title":""},{"content":"","date":null,"permalink":"http://localhost:1313/posts/","section":"","summary":"","title":""},{"content":"AI-generated images are more visually stunning than ever, but how do they really stack up against natural, real-world photos? We introduce D-Judge, a large-scale benchmark designed to systematically investigate and quantify the discrepancies that remain.\nDespite the rapid progress of generative models, AI-generated images (AIGIs) often fall short of real-world application standards. Existing evaluation methods provide an incomplete picture. They often focus on a narrow set of metrics like perceptual quality or text alignment, use small datasets, and primarily consider simple text-to-image prompts, neglecting more complex multimodal guidance.\nKey Problem: There\u0026rsquo;s no systematic, comprehensive way to measure the fine-grained differences between AI-generated and natural images, which is crucial for understanding model limitations and driving meaningful progress. ğŸ“„ Paper ğŸ“ Code ğŸ¤— Dataset What We Built #Our work introduces two core contributions to tackle this challenge:\nThe D-ANI Dataset: A massive new multimodal dataset featuring over 440,000 AI-generated images from 9 representative models (from GANs to DALL-E 3). It\u0026rsquo;s the first to include images generated from unimodal (Text-to-Image, Image-to-Image) and multimodal (Text-and-Image-to-Image) prompts. The D-Judge Framework: A fine-grained evaluation framework that assesses discrepancies across five crucial dimensions: naive visual quality, semantic alignment, aesthetic appeal, downstream task applicability, and coordinated human validation. Method \u0026amp; System #1. Framework Overview #D-Judge systematically compares AI-generated images with their natural counterparts. For a given prompt, we generate an AIGI and pair it with a real reference image. The framework then assesses the \u0026ldquo;Discrepancy Rate\u0026rdquo; (DR) between the two across our five dimensions, integrating both automated metrics and human judgment for a holistic view.\nFigure 1. The D-Judge framework evaluates discrepancies across five dimensions, complemented by human validation. 2. The D-ANI Dataset # Our Massive Dataset At the heart of our benchmark is the D-ANI (Distinguishing Natural and AI-generated) dataset. We started with 5,000 high-quality natural images from the MS COCO dataset, each with at least five captions. We then used these text-image pairs to prompt nine different generative models to create a diverse collection of over 440,000 AIGIs.\nModels: Includes GANs (GALIP, DF-GAN), various Stable Diffusion versions (v1.4, v1.5, v2.1, XL), Versatile Diffusion, and OpenAI\u0026rsquo;s DALL-E 2 \u0026amp; 3. Prompts: Uniquely covers Text-to-Image (T2I), Image-to-Image (I2I), and Text-and-Image-to-Image (TI2I) guidance. Figure 2. Our D-ANI dataset includes 440,000+ images from 9 models, guided by three types of prompts. Representative Findings #Our extensive experiments reveal that while AIGIs are impressive, significant gaps remain.\nKey Discrepancies Revealed\nLarge Gaps Persist: AIGIs show substantial discrepancies from natural images, with difference rates of up to 40% in image quality, 33.57% in semantic alignment, and a staggering 96.95% in downstream task applicability (specifically VQA). Downstream Tasks Suffer: The poor performance in downstream tasks like fine-grained object recognition and VQA highlights that current models struggle with practical, real-world utility. Text Guidance is Key: Images generated with text prompts (T2I and TI2I) show much better semantic alignment than those generated from an image prompt alone (I2I). Human vs. Machine Evaluation: Human evaluators consistently identify larger discrepancies in quality, alignment, and aesthetics than our automated metrics do. This shows that current metrics don\u0026rsquo;t fully capture human perception and validates the need for human-in-the-loop evaluation. Category Matters: The gap between AI and natural images varies significantly across different content categories (e.g., \u0026ldquo;animal\u0026rdquo; vs. \u0026ldquo;accessory\u0026rdquo;), likely due to imbalances in training data. DALL-E 3, for instance, showed the most pronounced deviations, possibly due to its tendency to generate more stylized imagery. Citation #Reference (ACM MM \u0026lsquo;25, Dublin, Ireland):\nRenyang Liu, Ziyu Lyu, Wei Zhou, and See-Kiong Ng. 2025. D-Judge: How Far Are We? Assessing the Discrepancies Between AI-synthesized and Natural Images through Multimodal Guidance. In Proceedings of the 33rd ACM International Conference on Multimedia (MM \u0026lsquo;25). ACM, New York, NY, USA, 19 pages. https://arxiv.org/pdf/2412.17632\nBibTeX @article{liu2024d, title={D-Judge: How Far Are We? Evaluating the Discrepancies Between AI-synthesized Images and Natural Images through Multimodal Guidance}, author={Liu, Renyang and Lyu, Ziyu and Zhou, Wei and Ng, See-Kiong}, journal={arXiv preprint arXiv:2412.17632}, year={2024} } ","date":"July 30 2025","permalink":"http://localhost:1313/posts/djudge/","section":"","summary":"\u003cp\u003eAI-generated images are more visually stunning than ever, but how do they really stack up against natural, real-world photos? We introduce D-Judge, a large-scale benchmark designed to systematically investigate and quantify the discrepancies that remain.\u003c/p\u003e","title":"D-Judge: How Far Are We? Accessing the Discrepancies Between AI-synthesized Images and Natural Images through Multimodal Guidance"},{"content":"","date":null,"permalink":"http://localhost:1313/tags/bias-evaluation/","section":"Tags","summary":"","title":"Bias Evaluation"},{"content":"","date":null,"permalink":"http://localhost:1313/categories/","section":"Categories","summary":"","title":"Categories"},{"content":"","date":null,"permalink":"http://localhost:1313/tags/fairness/","section":"Tags","summary":"","title":"Fairness"},{"content":"Dual-perspective, dual-granularity fairness evaluation for LLM-based job recommendation: we assess bias from both the user and the recruiter sides, at individual and group levels.\nWhy FairWork #Large Language Models (LLMs) enable highly personalized recommendations, but their inherent biases can harm fairness in job recommendation, affecting users and platforms alike. While prior work often covers limited dimensions, FairWork provides a comprehensive view.\nKey Problem: Existing fairness evaluation methods for job recommendation systems have limited scope and don\u0026rsquo;t account for the complex bias patterns that emerge when LLMs are used for recommendation tasks. ğŸ¤— Demo ğŸ“ Code What We Built #Our framework addresses fairness evaluation through multiple dimensions:\nTwo perspectives: fairness for users and recruiters Two granularities: individual-level and group-level evaluation Realistic inputs: stakeholders upload profiles and job descriptions; we align candidate qualifications with job requirements Actionable metrics \u0026amp; analysis: sensitivity to custom attributes and their intersections; quantitative fairness metrics (SPD, EO, PPV) and background analysis Method \u0026amp; System #1. Framework Overview # Figure 1. Individual- and Group-level fairness evaluation workflow. Counterfactual perturbation. We inject alternative values for sensitive attributes to build a perturbed profile $x\u0026rsquo;_u=\\text{Perturb}(x_u, C_u)$, then query the same LLM prompt for original and perturbed profiles to obtain prediction scores and compare outcomes across settings.\n2. Individual-level Pipeline # Individual Analysis Inputs: one user profile + job description Candidate Matching: Adopt TF-IDF to retrieve resumes similar to the user\u0026rsquo;s profile; if insufficient, synthetic profiles are generated by the LLM to ensure adequate comparison candidates Ranking Comparison: Analyze rank changes of the original candidate among perturbed profiles to quantify fairness deviations Individual Input Interface Individual Output Results 3. Group-level Pipeline # Group Analysis Inputs: dataset + specified sensitive attributes Industry-specific Sampling: Aggregate jobs by industry, then sample representative job postings to match with user profiles Evaluation: Evaluate system-wide fairness with standard metrics (SPD, EO, PPV diff), sensitivity scores (Pred diff), and detailed background analysis (educational \u0026amp; professional distribution) We also employ an adaptive injection strategy to keep diversity while controlling compute when intersections grow combinatorially Group-level Fairness Metrics Detailed Background Analysis Data \u0026amp; Settings # Dataset: We include the public CareerBuilder job recommendation dataset (â‰ˆ321,235 users, 365,668 jobs), preprocessed and clustered by industry. Demo case study: sample 150 users and 5 jobs/user; evaluate Age and Gender on Deepseek-v3 and Llama3-8b; deterministic decoding with temperature=0.\nRepresentative Findings #Our comprehensive evaluation revealed several important patterns:\nIntersectional Effects # Age \u0026amp; Gender combined yields larger bias than either attribute alone Intersectional bias patterns vary significantly across different industries Model Differences # Deepseek-v3 shows larger group-level gaps: SPD: 0.0187 EO: 0.0299 Llama3-8b demonstrates more controlled bias: SPD: 0.0053 EO: 0.0074 Industry-Specific Patterns # Key Finding: Bias patterns are highly industry-dependent and vary between different LLM models. Deepseek-v3: Bias peaks in Sales (Age/Gender) and Education (Age\u0026amp;Gender) Llama3-8b: Age bias notable in Education/Healthcare Gender bias in Technology Age\u0026amp;Gender bias in Administrative/Healthcare How to Use #Individual-level Evaluation # Upload one user profile and one job description Optionally set your sensitive-attribute values The system retrieves similar candidates (TF-IDF; synthesizes profiles if needed) Perturbs attributes and compares rankings Group-level Evaluation # Upload a dataset (profiles + JDs + optional interaction labels) Choose sensitive attributes The system performs industry-aware sampling Runs metrics for user/recruiter perspectives Citation #Reference (SIGIR \u0026lsquo;25, Padua, Italy):\nYuhan Hu, Ziyu Lyu, Lu Bai, and Lixin Cui. 2025. FairWork: A Generic Framework For Evaluating Fairness In LLM-Based Job Recommender System. In Proceedings of the 48th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR \u0026lsquo;25), July 13â€“18, 2025, Padua, Italy. ACM, New York, NY, USA, 5 pages. https://doi.org/10.1145/3726302.3730145\nBibTeX @inproceedings{Hu2025FairWork, title = {FairWork: A Generic Framework For Evaluating Fairness In LLM-Based Job Recommender System}, author = {Yuhan Hu and Ziyu Lyu and Lu Bai and Lixin Cui}, booktitle = {Proceedings of the 48th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR \u0026#39;25)}, year = {2025}, address = {Padua, Italy}, doi = {10.1145/3726302.3730145} } ","date":"January 15 2025","permalink":"http://localhost:1313/posts/fairwork2/","section":"","summary":"\u003cp\u003eDual-perspective, dual-granularity fairness evaluation for LLM-based job recommendation: we assess bias from both the user and the recruiter sides, at individual and group levels.\u003c/p\u003e","title":"FairWork: A Generic Framework For Evaluating Fairness In LLM-Based Job Recommender System"},{"content":"","date":null,"permalink":"http://localhost:1313/tags/job-recommendation/","section":"Tags","summary":"","title":"Job Recommendation"},{"content":"","date":null,"permalink":"http://localhost:1313/tags/llm/","section":"Tags","summary":"","title":"LLM"},{"content":"","date":null,"permalink":"http://localhost:1313/categories/publication/","section":"Categories","summary":"","title":"Publication"},{"content":"","date":null,"permalink":"http://localhost:1313/categories/research/","section":"Categories","summary":"","title":"Research"},{"content":"","date":null,"permalink":"http://localhost:1313/tags/","section":"Tags","summary":"","title":"Tags"},{"content":"","date":null,"permalink":"http://localhost:1313/tags/ai-safety/","section":"Tags","summary":"","title":"AI Safety"},{"content":"Large Language Models (LLMs) need to be both helpful and safe, but achieving both is a major challenge. We propose MidPO, a Mixture of Experts (MoE) framework that fine-tunes two specialized experts for safety and helpfulness and uses a dynamic routing mechanism to adaptively balance them, outperforming existing methods.\nThe Safety vs. Helpfulness Dilemma #Aligning Large Language Models (LLMs) is a delicate balancing act. Current methods often force a trade-off between being helpful and being safe.\nOnline alignment methods (like RLHF) can be overly cautious, leading them to refuse safe, harmless prompts. This is known as the \u0026ldquo;excessive safety\u0026rdquo; or \u0026ldquo;over-refusal\u0026rdquo; problem. Offline alignment methods (like DPO variants) often fail to adapt, sometimes providing helpful but harmful responses to unsafe prompts. Key Problem: Existing alignment techniques struggle to create LLMs that are both robustly safe against harmful queries and genuinely helpful for safe ones, often sacrificing one for the other. ğŸ“„ Paper ğŸ“ Code (to be released) What We Built: The MidPO Framework #Our framework, MidPO (Mixture of Experts Dual Preference Optimization), addresses this challenge with two core components:\nTwo Specialized Experts: Instead of a one-size-fits-all model, we train two distinct experts: a Safety Expert and a Helpfulness Expert. We use our novel Single-Preference Enhanced DPO (SPE-DPO) method to make each expert highly proficient in its domain. A Dynamic Routing Mechanism: A smart \u0026ldquo;router\u0026rdquo; analyzes the user\u0026rsquo;s prompt and adaptively decides how much to listen to the Safety Expert versus the Helpfulness Expert. This allows the model to be cautious with unsafe prompts but open and helpful with safe ones. Efficient Offline Alignment: The entire framework is built on an offline alignment process, making it more stable and computationally efficient than online RLHF-based methods. Method \u0026amp; System # Framework Overview MidPO first transforms a base LLM into two specialized experts using LoRA fine-tuning with our SPE-DPO loss functions. Then, it freezes the experts and trains a dynamic router that learns to combine their contributions effectively for any given prompt, achieving a superior balance between safety and helpfulness. Figure 1. The MidPO framework, showing (a) the training of single-preference experts and (b) the dynamic routing mechanism. Single-Preference Enhanced Experts (SPE-DPO) The foundation of MidPO is creating highly specialized experts. Our proposed SPE-DPO method is designed for single-preference optimization. By introducing a homogeneous preference margin, it amplifies the distinction between good and bad responses within a single category (e.g., safe vs. unsafe), making the experts more effective than if they were trained with standard DPO.\nDynamic Routing Mechanism This is where the magic happens. The router analyzes the input prompt and assigns a weight to the Safety and Helpfulness experts. For an unsafe question (e.g., \u0026ldquo;How to do X illegal thing?\u0026rdquo;), it gives more weight to the Safety Expert. For a safe question (e.g., \u0026ldquo;How do I make my wife laugh?\u0026rdquo;), it prioritizes the Helpfulness Expert. This adaptive approach ensures the final response is context-appropriately safe and helpful.\nData \u0026amp; Settings # Base Model: We built MidPO on top of the widely used Alpaca-7B model.\nDatasets: We trained and evaluated MidPO on three popular benchmarks:\nPKU-Safe RLHF , Do Not Answer , and Wildguard Mix.\nWe compared MidPO against strong baselines, including\nSafe RLHF (an online method) and MODPO (an offline method), ensuring a fair comparison by using the same base model for all methods where possible.\nRepresentative Findings #Our comprehensive evaluation showed that MidPO sets a new standard for balancing safety and helpfulness.\nUnprecedented Balance MidPO consistently achieves the highest scores for both safety and helpfulness across all three datasets, significantly outperforming all baselines. Other methods either excel at one while failing at the other or are mediocre at both.\nFigure 2. MidPO (top right) achieves a superior balance of safety and helpfulness compared to baselines across three different datasets. Superior Experts and Routing # Better Experts: Our experts, fine-tuned with SPE-DPO, demonstrated superior single-preference performance compared to experts trained with vanilla DPO.\nEffective Routing: Ablation studies confirmed the crucial role of the dynamic routing mechanism. Removing it led to a significant drop in both safety (19.25% win rate) and helpfulness (13.62% win rate).\nKey Finding: The combination of highly specialized experts and an adaptive routing mechanism allows MidPO to navigate the safety-helpfulness trade-off more effectively than any previous method. Citation #Reference (arXiv Preprint):\nYupeng Qi, Ziyu Lyu, Min Yang, Yanlin Wang, Lu Bai, Lixin Cui. 2025. MidPO: Dual Preference Optimization for Safety and Helpfulness in Large Language Models via a Mixture of Experts Framework. arXiv preprint arXiv:2506.02460.\nBibTeX Code snippet\n@misc{qi2025midpo, title={MidPO: Dual Preference Optimization for Safety and Helpfulness in Large Language Models via a Mixture of Experts Framework}, author={Yupeng Qi and Ziyu Lyu and Min Yang and Yanlin Wang and Lu Bai and Lixin Cui}, year={2025}, eprint={2506.02460}, archivePrefix={arXiv}, primaryClass={cs.CL} }\n","date":"January 10 2025","permalink":"http://localhost:1313/posts/midpo/","section":"","summary":"\u003cp\u003eLarge Language Models (LLMs) need to be both helpful and safe, but achieving both is a major challenge. We propose MidPO, a Mixture of Experts (MoE) framework that fine-tunes two specialized experts for safety and helpfulness and uses a dynamic routing mechanism to adaptively balance them, outperforming existing methods.\u003c/p\u003e","title":"MidPO: Dual Preference Optimization for Safety and Helpfulness in Large Language Models via a Mixture of Experts Framework"},{"content":"","date":null,"permalink":"http://localhost:1313/tags/mixture-of-experts/","section":"Tags","summary":"","title":"Mixture of Experts"},{"content":"","date":null,"permalink":"http://localhost:1313/tags/preference-optimization/","section":"Tags","summary":"","title":"Preference Optimization"},{"content":"After careful design and development, the official website of the Knowledge Intelligence Lab (KILab) at Sun Yat-sen University is now fully upgraded and online! The new website adopts modern design concepts, providing visitors with a clearer and more intuitive browsing experience.\nKey Features # Responsive Design: Perfect adaptation to various device screens Rich Content: Covering research directions, team introductions, academic achievements, etc. Real-time Updates: Timely publication of the latest research developments and academic information Website Content #The new website includes the following main sections:\nLaboratory introduction and research framework Team member introductions Research resources and datasets Academic papers and conference information Laboratory activity updates Welcome everyone to visit our new website and learn about the latest developments of our laboratory!\n","date":"January 1 2025","permalink":"http://localhost:1313/posts/website-launch/","section":"","summary":"\u003cp\u003eAfter careful design and development, the official website of the Knowledge Intelligence Lab (KILab) at Sun Yat-sen University is now fully upgraded and online! The new website adopts modern design concepts, providing visitors with a clearer and more intuitive browsing experience.\u003c/p\u003e","title":"ğŸŠ Official Lab Website Launched"},{"content":"","date":null,"permalink":"http://localhost:1313/tags/announcement/","section":"Tags","summary":"","title":"Announcement"},{"content":"","date":null,"permalink":"http://localhost:1313/tags/website/","section":"Tags","summary":"","title":"Website"},{"content":"","date":null,"permalink":"http://localhost:1313/tags/faculty/","section":"Tags","summary":"","title":"Faculty"},{"content":"We are pleased to announce that Professor Ziyu Lyu officially joined the School of Cyber Science and Technology at Sun Yat-sen University in September 2023, serving as Associate Professor and Ph.D. Supervisor.\nAcademic Background #Professor Lyu has extensive research experience and outstanding academic achievements in artificial intelligence safety, intelligent information retrieval, natural language processing, and related fields. His joining will further strengthen our school\u0026rsquo;s capabilities in these research areas.\nResearch Directions #Professor Lyu\u0026rsquo;s main research directions include:\nTrustworthy artificial intelligence algorithms AI-generated content (AIGC) security Recommender systems and user modeling Large language models (LLM) Multimodal knowledge extraction and reasoning Laboratory Development #Under Professor Lyu\u0026rsquo;s leadership, the Knowledge Intelligence Lab (KILab) will be dedicated to advancing cutting-edge research, cultivating excellent talents, and contributing to the secure and trustworthy development of artificial intelligence technology.\nWe look forward to achieving more breakthrough results together with Professor Lyu on the academic journey!\n","date":"September 1 2023","permalink":"http://localhost:1313/posts/professor-joins-sysu/","section":"","summary":"\u003cp\u003eWe are pleased to announce that Professor Ziyu Lyu officially joined the School of Cyber Science and Technology at Sun Yat-sen University in September 2023, serving as Associate Professor and Ph.D. Supervisor.\u003c/p\u003e","title":"Professor Ziyu Lyu Joins SYSU School of Cyber Science and Technology"},{"content":"","date":"January 1 0001","permalink":"http://localhost:1313/lab_activities/","section":"","summary":"","title":""},{"content":"","date":"January 1 0001","permalink":"http://localhost:1313/team/","section":"","summary":"","title":""},{"content":"Important Conference Deadlines #To facilitate lab members and academic colleagues in tracking important conference submission deadlines, we have compiled information about major conferences in related fields.\nReal-time Updates: We recommend using professional conference deadline tracking websites for the latest information Recommended Conference Deadline Tracking Websites #Main Tracking Platforms # Conference Deadlines (ccfddl.github.io) #The most comprehensive CS conference deadline tracking website, supporting multi-domain filtering with a user-friendly interface and timely updates.\nVisit Website AI Deadlines (aideadlin.es) #Focused on AI conference deadlines, including machine learning, natural language processing, computer vision, and more.\nVisit Website Call for Papers #Detailed conference call for papers information, including conference themes, submission requirements, and important dates.\nVisit Website Key Focus Conferences (2025) #Top-tier AI Conferences (CCF-A) # AAAI 2025 Deadline Passed # Deadline: August 15, 2024 Conference Date: February 25 - March 4, 2025 Location: Philadelphia, USA Website: aaai.org/aaai25 IJCAI 2025 Opening Soon # Deadline: January 13, 2025 (expected) Conference Date: August 16-22, 2025 Location: Montreal, Canada Website: ijcai25.org SIGKDD 2025 Opening Soon # Deadline: February 6, 2025 (expected) Conference Date: August 24-28, 2025 Location: Toronto, Canada Website: kdd.org/kdd2025 Natural Language Processing Conferences # ACL 2025 Deadline Passed # Deadline: October 15, 2024 Conference Date: July 27 - August 1, 2025 Location: Vienna, Austria Website: 2025.aclweb.org EMNLP 2025 Not Announced # Deadline: June 15, 2025 (expected) Conference Date: November 2025 (expected) Location: TBD Website: To be updated Machine Learning Conferences # ICLR 2025 In Progress # Deadline: October 1, 2024 Conference Date: April 24 - May 2, 2025 Location: Singapore Website: iclr.cc/Conferences/2025 ICML 2025 Opening Soon # Deadline: January 31, 2025 (expected) Conference Date: July 2025 (expected) Location: TBD Website: To be updated Quick Filtering Tools #Filter by Research Area # Knowledge Graphs #Key Conferences:\nAAAI, IJCAI, SIGKDD (CCF-A) CIKM, WSDM, ISWC (CCF-B) ESWC, K-CAP (Specialized conferences) Journals:\nKnowledge-Based Systems (SCI Q1) Semantic Web Journal (SCI Q2) Natural Language Processing #Key Conferences:\nACL, EMNLP, NAACL (CCF-A) COLING, AAAI (CCF-A/B) CoNLL, *SEM (Specialized conferences) Journals:\nComputational Linguistics (SCI Q1) TACL, TASLP (SCI Q1/Q2) Machine Learning #Key Conferences:\nICML, NeurIPS, ICLR (CCF-A) AAAI, IJCAI (CCF-A) UAI, AISTATS (CCF-B) Journals:\nJMLR, ML (SCI Q1) IEEE TPAMI (SCI Q1) Submission Recommendations # Submission Strategy Recommendations:\nStart preparing 2-3 months in advance Pay attention to conference special tracks and workshops Be mindful of time zone differences, avoid last-minute submissions Prepare backup options for multiple conferences Set Reminders: It\u0026rsquo;s recommended to set advance reminders in your calendar to ensure you don\u0026rsquo;t miss important deadlines Additional Resources # CCF Recommended Conference List: China Computer Federation Recommended International Academic Conferences Conference Ranking Reference: CSRankings Submission Experience Sharing: Academic Writing and Submission Tips ","date":"January 1 0001","permalink":"http://localhost:1313/conference_deadlines/","section":"","summary":"\u003ch2 id=\"important-conference-deadlines\" class=\"relative group\"\u003eImportant Conference Deadlines \u003cspan class=\"absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100\"\u003e\u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\" style=\"text-decoration-line: none !important;\" href=\"#important-conference-deadlines\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\u003c/span\u003e\u003c/h2\u003e\u003cp\u003eTo facilitate lab members and academic colleagues in tracking important conference submission deadlines, we have compiled information about major conferences in related fields.\u003c/p\u003e","title":"Conference Deadlines"},{"content":" Page Under Construction: This page is being developed. Stay tuned! Upcoming Exciting Content #We are preparing rich and diverse lab activity content, including:\nAcademic Activities # ğŸ“š Academic Seminars: Regularly inviting domestic and international experts to share the latest research findings ğŸ“ Study Groups: Weekly paper reading and technical discussions ğŸ† Academic Competitions: Participating in various AI and data mining competitions Team Building # ğŸ‰ Lab Dinners: Regular gatherings to strengthen team bonds ğŸš€ Team Building Activities: Outdoor development and team collaboration activities ğŸ‚ Birthday Parties: Celebrating lab members\u0026rsquo; birthdays Cultural Activities # ğŸ“¸ Lab Photography: Recording beautiful research moments ğŸ® Leisure Activities: Relaxing activities during spare time ğŸŒŸ Festival Celebrations: Celebrating traditional festivals and important milestones Stay tuned for more exciting lab activity content! ","date":null,"permalink":"http://localhost:1313/activities/","section":"Lab Activities","summary":"\u003cdiv class=\"flex rounded-md bg-primary-100 px-4 py-3 dark:bg-primary-900\"\u003e\n  \u003cspan class=\"pe-3 text-primary-400\"\u003e\n    \u003cspan class=\"icon relative inline-block px-1 align-text-bottom\"\u003e\u003csvg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 512 512\"\u003e\u003cpath fill=\"currentColor\" d=\"M506.3 417l-213.3-364c-16.33-28-57.54-28-73.98 0l-213.2 364C-10.59 444.9 9.849 480 42.74 480h426.6C502.1 480 522.6 445 506.3 417zM232 168c0-13.25 10.75-24 24-24S280 154.8 280 168v128c0 13.25-10.75 24-23.1 24S232 309.3 232 296V168zM256 416c-17.36 0-31.44-14.08-31.44-31.44c0-17.36 14.07-31.44 31.44-31.44s31.44 14.08 31.44 31.44C287.4 401.9 273.4 416 256 416z\"/\u003e\u003c/svg\u003e\n\u003c/span\u003e\n  \u003c/span\u003e\n  \u003cspan class=\"dark:text-neutral-300\"\u003e\u003cstrong\u003ePage Under Construction\u003c/strong\u003e: This page is being developed. Stay tuned!\u003c/span\u003e\n\u003c/div\u003e\n\n\u003ch2 id=\"upcoming-exciting-content\" class=\"relative group\"\u003eUpcoming Exciting Content \u003cspan class=\"absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100\"\u003e\u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\" style=\"text-decoration-line: none !important;\" href=\"#upcoming-exciting-content\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\u003c/span\u003e\u003c/h2\u003e\u003cp\u003eWe are preparing rich and diverse lab activity content, including:\u003c/p\u003e","title":"Lab Activities"},{"content":"We are committed to promoting open research in the field of knowledge intelligence, sharing our research projects, datasets, benchmarks, and tools with the academic and industrial communities.\nResearch Projects #Our research focuses on cutting-edge fields including trustworthy artificial intelligence, intelligent information retrieval, natural language processing, and knowledge intelligence applications, committed to promoting the deep integration of theoretical innovation and practical applications.\nAI Security and Trust #In today\u0026rsquo;s rapidly evolving AI landscape, ensuring the security and trustworthiness of AI systems is crucial. We conduct in-depth research in this frontier field:\nCore Research Areas:\nTrustworthy AI Algorithms: Design AI algorithms with robustness, explainability, and fairness AIGC Security: Research on security risks and protection mechanisms for AI-generated content AI Model Reliability: Enhance the stability of deep learning models under adversarial attacks Privacy-Preserving AI: Develop federated learning and differential privacy technologies to protect user privacy Intelligent Information Retrieval #Information retrieval is the key technology connecting user needs with massive information. We focus on personalized and intelligent information retrieval system research:\nCore Research Areas:\nRecommendation Systems: Deep learning-based personalized recommendation algorithms User Modeling and Understanding: Multi-dimensional user profiling and behavior prediction Knowledge Acquisition: Automatic acquisition of structured knowledge from multi-source heterogeneous data Search Technologies: Next-generation intelligent search engine technologies Natural Language Processing #Natural language processing is the core technology for achieving intelligent human-machine interaction. We conduct cutting-edge research in large-scale language models and multimodal understanding:\nCore Research Areas:\nLarge Language Models (LLM): Optimization and application of pre-trained models Multimodal Knowledge Extraction: Knowledge extraction fusing visual and linguistic information Knowledge Representation Learning: Vectorized representation and reasoning of textual knowledge Dialogue Systems: Knowledge-driven intelligent dialogue technologies Spatial-Temporal Analysis and Prediction #Spatial-temporal data analysis has important application value in intelligent transportation, urban computing, and other fields:\nCore Research Areas:\nLocation-aware Social Network Analysis: Geographic location-based social behavior modeling Real-time Push Algorithms: Spatial-temporal aware information push systems Traffic Data Analysis: Data mining and prediction for intelligent transportation systems Time Series Prediction: Deep learning prediction models for multivariate time series Knowledge Intelligence Applications #Apply knowledge intelligence technologies to real industry scenarios, solving complex real-world problems:\nCore Research Areas:\nIntelligent Finance: Knowledge graph-based financial risk control and investment decision-making Intelligent Transportation: Traffic flow optimization and intelligent navigation systems Recommendation System Applications: Industrial applications in e-commerce, content recommendation, and other fields Multimedia Content Understanding: Intelligent analysis and understanding of videos and images Research Project Support: The laboratory leads multiple important research projects including National Natural Science Foundation, Guangdong Natural Science Foundation, CCF-DiDi GAIA Young Scholar Program, and others. Datasets #Knowledge Graph Datasets # CN-Academic-KG #Chinese Academic Knowledge Graph\nA large-scale knowledge graph containing over 1 million Chinese academic entities and relationships, covering multiple disciplines including computer science, mathematics, and physics.\nGitHub Paper MultiModal-KG #Multimodal Knowledge Graph\nA multimodal knowledge graph that integrates textual, visual, and numerical information, containing over 500K entities and 2M+ triples.\nGitHub Paper Natural Language Processing Datasets # FewShot-RE-ZH #Chinese Few-Shot Relation Extraction\nA dataset specifically designed for Chinese few-shot relation extraction, containing 20 relation categories with only 1-5 annotated samples per category.\nGitHub Paper Dialogue-KG #Dialogue Knowledge Graph\nA knowledge graph built from real dialogues, used to evaluate the knowledge reasoning capabilities of dialogue systems.\nGitHub Paper Benchmarks #KG-Benchmark Suite # We have developed a comprehensive knowledge graph benchmark suite covering multiple core tasks:\nEntity Linking # Dataset: 5 domains, 100K+ annotated samples Evaluation Metrics: Precision, Recall, F1-Score Baseline Models: 10 SOTA model comparisons Relation Extraction # Dataset: Bilingual (Chinese-English), 50 relation types Evaluation Metrics: Micro/Macro F1, AUC Baseline Models: 15 classic and state-of-the-art models Knowledge Reasoning # Dataset: Multi-hop reasoning, complex queries Evaluation Metrics: MRR, Hits@K Baseline Models: 8 graph neural network models GitHub Online Evaluation Open Source Tools #KG-Toolkit # All-in-One Knowledge Graph Toolkit\nA Python toolkit that integrates knowledge extraction, reasoning, and visualization capabilities # Installation pip install kg-toolkit # Usage Example from kg_toolkit import KnowledgeGraph, EntityExtractor # Create knowledge graph kg = KnowledgeGraph() # Entity extraction extractor = EntityExtractor(model=\u0026#39;bert-base-chinese\u0026#39;) entities = extractor.extract(\u0026#34;Zhang San is a professor at Sun Yat-sen University\u0026#34;) Key Features:\nğŸš€ Multiple pre-trained model support ğŸ“Š Knowledge graph visualization ğŸ”§ Flexible API interface ğŸ“š Detailed documentation and tutorials GitHub PyPI NLP-Utils # Natural Language Processing Utilities\nContains practical functions for text preprocessing, feature extraction, and model evaluation Main Modules:\nChinese text segmentation and POS tagging Named entity recognition Relation extraction Text classification Semantic similarity computation GitHub Tutorials and Documentation #Getting Started Tutorials # Knowledge Graph Fundamentals #A beginner-friendly knowledge graph tutorial covering theoretical foundations and practical operations. Start Learning Graph Neural Networks in Practice #An accessible introduction to the principles and implementation of graph neural networks. Start Learning NLP Pipeline #A complete NLP project tutorial from data preprocessing to model deployment. Start Learning Technical Blog #Regularly updated technical blog sharing latest research findings and technical insights:\nApplications of Knowledge Graphs in Recommender Systems Recent Advances in Few-Shot Learning Development Trends in Multimodal AI Contribution Guidelines: We welcome community contributions including code, issue reports, and improvement suggestions! Please check the CONTRIBUTING.md file in each project for details. Contact Us: For technical support or collaboration, please email contact@kilab.org ","date":null,"permalink":"http://localhost:1313/resources/","section":"Resources","summary":"\u003cp\u003eWe are committed to promoting open research in the field of knowledge intelligence, sharing our research projects, datasets, benchmarks, and tools with the academic and industrial communities.\u003c/p\u003e","title":"Resources"},{"content":" (* corresponding author, #supervised students)\nD-Judge: How Far Are We? Assessing the Discrepancies Between AI-synthesized Images and Natural Images through Multimodal Guidance #Authors: Renyang Liu#, Ziyu Lyu*, Wei Zhou, See-Kiong Ng\nConference: ACM International Conference on Multimedia (MM), 2025\nRank: CCF-A\nShiftKD: Benchmarking knowledge distillation under distribution shift #Authors: Songming Zhang#, Yuxiao Luo#, Ziyu Lyu*, Xiaofeng Chen\nJournal: Neural Networks, Volume 192, December 2025, 107838\nEGRec: Leveraging Generative Rich Intents for Enhanced Recommendation with Large Language Models #Authors: Zhaorui Lian#, Binzong Geng, Xiyu Chang, Yu Zhang, Ke Ding, Ziyu Lyu*, Guanghu Yuan, Chengming Li, Min Yang*, Zhaoxin Huan, Bin Shen, Yong He, Linjian Mo, Liang Zhang, Xing Zhu\nConference: Proceedings of The Web Conference 2025 (WWW'25), Sydney, Australia, 28 April - 2 May 2025\nFairWork: A Generic Framework For Evaluating Fairness In LLM-Based Job Recommender System #Authors: Yuhan Hu#, Ziyu Lyu*, Lu Bai, and Lixin Cui\nConference: Proceedings of the 48th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR \u0026lsquo;25 Demo)\nENAHPool: The Edge-Node Attention-based Hierarchical Pooling for Graph Neural Networks #Authors: Zhehan Zhao, Lu Bai, Lixin Cui, Ming Li, Ziyu Lyu, Lixiang Xu, Yue Wang, Edwin Hancock\nConference: 42th International Conference on Machine Learning (ICML'25)\nDHAKR: Learning Deep Hierarchical Attention-Based Kernelized Representations for Graph Classification #Authors: Feifei Qian, Lu Bai, Lixin Cui, Ming Li, Ziyu Lyu, Hangyuan Du, Edwin Hancock\nConference: Proceedings of the AAAI Conference on Artificial Intelligence (AAAI'25)\nTFDNet: Time-Frequency Enhanced Decomposed Network for Long-term Time Series Forecasting #Authors: Yuxiao Luo#, Songming Zhang, Ziyu Lyu*, Yuhan Hu\nJournal: Pattern Recognition, Volume 162, 2025\nKnowledge Enhanced Graph Neural Networks for Explainable Recommendation #Authors: Ziyu Lyu, Yue Wu, Junjie Lai, Min Yang, Chengming Li, Wei Zhou\nJournal: IEEE Transactions on Knowledge and Data Engineering (TKDE), 2023, vol. 35, no. 5, pp. 4954-4968 Rank: CCF-A / JCR Q1\nInformation Retrieval Meets Large Language Models: A Strategic Report from Chinese IR Community #Authors: Qingyao Ai, Ting Bai, Zhao Cao, Yi Chang, Jiawei Chen, Zhumin Chen, Zhiyong Cheng, Shoubin Dong, Zhicheng Dou, Fuli Feng, Shen Gao, Jiafeng Guo, Xiangnan He, Yanyan Lan, Chenliang Li, Yiqun Liu, Ziyu Lyu, Weizhi Ma, Jun Ma, Zhaochun Ren, Pengjie Ren, Zhiqiang Wang, Mingwen Wang, Ji-Rong Wen, Le Wu, Xin Xin, Jun Xu, Dawei Yin, Peng Zhang, Fan Zhang, Weinan Zhang, Min Zhang, Xiaofei Zhu\nJournal: AI Open, Volume 4, 2023, Pages 80-90\nVisual Knowledge Graph for Human Action Reasoning in Videos #Authors: Yue Ma#, Yali Wang, Yue Wu#, Ziyu Lyu, Siran Chen, Xiu Li, Yu Qiao\nConference: Proceedings of the 29th ACM International Conference on Multimedia (MM), Lisbon, October, 2022 Rank: CCF-A\nMulti-task Learning for Recommendation over Heterogeneous Information Network #Authors: Hui Li, Yanlin Wang, Ziyu Lyu, Jieming Shi\nJournal: IEEE Transactions on Knowledge and Data Engineering (TKDE), 2022\n","date":null,"permalink":"http://localhost:1313/publications/","section":"SELECTED PUBLICATIONS","summary":"\u003cblockquote\u003e\n\u003cp\u003e(* corresponding author, #supervised students)\u003c/p\u003e\u003c/blockquote\u003e\n\u003ch4 id=\"hahahugoshortcode14s0hbhb-d-judge-how-far-are-we-assessing-the-discrepancies-between-ai-synthesized-images-and-natural-images-through-multimodal-guidance\" class=\"relative group\"\u003e\n\n  \u003cspan class=\"icon relative inline-block align-text-bottom\"\u003e\n    \u003csvg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 512 512\"\u003e\u003cpath fill=\"currentColor\" d=\"M421.7 220.3L188.5 453.4L154.6 419.5L158.1 416H112C103.2 416 96 408.8 96 400V353.9L92.51 357.4C87.78 362.2 84.31 368 82.42 374.4L59.44 452.6L137.6 429.6C143.1 427.7 149.8 424.2 154.6 419.5L188.5 453.4C178.1 463.8 165.2 471.5 151.1 475.6L30.77 511C22.35 513.5 13.24 511.2 7.03 504.1C.8198 498.8-1.502 489.7 .976 481.2L36.37 360.9C40.53 346.8 48.16 333.9 58.57 323.5L291.7 90.34L421.7 220.3zM492.7 58.75C517.7 83.74 517.7 124.3 492.7 149.3L444.3 197.7L314.3 67.72L362.7 19.32C387.7-5.678 428.3-5.678 453.3 19.32L492.7 58.75z\"/\u003e\u003c/svg\u003e\n\n  \u003c/span\u003e\n\n D-Judge: How Far Are We? Assessing the Discrepancies Between AI-synthesized Images and Natural Images through Multimodal Guidance \u003cspan class=\"absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100\"\u003e\u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\" style=\"text-decoration-line: none !important;\" href=\"#hahahugoshortcode14s0hbhb-d-judge-how-far-are-we-assessing-the-discrepancies-between-ai-synthesized-images-and-natural-images-through-multimodal-guidance\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\u003c/span\u003e\u003c/h4\u003e\u003cp\u003e\u003cstrong\u003eAuthors\u003c/strong\u003e: Renyang Liu#, Ziyu Lyu*, Wei Zhou, See-Kiong Ng\u003cbr\u003e\n\u003cstrong\u003eConference\u003c/strong\u003e: ACM International Conference on Multimedia (MM), 2025\u003cbr\u003e\n\u003cstrong\u003eRank\u003c/strong\u003e: CCF-A\u003c/p\u003e","title":"SELECTED PUBLICATIONS"},{"content":"ä¸­å±±å¤§å­¦ç½‘ç»œç©ºé—´å®‰å…¨å­¦é™¢ï¼ˆåœ°ç†ä½ç½®ï¼šæ·±åœ³æ ¡åŒºï¼‰å•å­é’°è¯¾é¢˜ç»„è¯šæ‹› 2026 ç§‹å­£å…¥å­¦åšå£«ç”Ÿ/ç¡•å£«ç”Ÿï¼Œé•¿æœŸæ‹›è˜åšå£«åå’Œå®ä¹ ç”Ÿï¼Œæœ‰æ„å‘ç”³è¯·2027 ç§‹å­£çš„åŒå­¦ï¼ˆç‰¹åˆ«æœ‰æ„ä¿ç ”çš„åŒå­¦ï¼‰ä¹Ÿå¯ä»¥è”ç³»æˆ–è€…å…ˆç”³è¯·å®ä¹ ç”Ÿã€‚è¯¾é¢˜ç»„å­¦æœ¯æ°›å›´æµ“åšã€æ¯å‘¨è‡³å°‘ä¸€æ¬¡1å¯¹1çš„å¯¼å¸ˆäº¤æµæŒ‡å¯¼ã€‚ä¼˜ç§€çš„å­¦ç”Ÿã€åšå£«åå¯ä»¥æ¨èåˆ°å›½å†…å¤–è‘—åé«˜æ ¡å’Œå›½å†…çŸ¥åç§‘æŠ€å…¬å¸äº¤æµã€è®¿å­¦ã€å®ä¹ ç­‰ã€‚\nç ”ç©¶æ–¹å‘ #å…·ä½“ç ”ç©¶æ–¹å‘å¦‚ä¸‹ï¼ˆä¸ä»…é™äºä»¥ä¸‹æ–¹å‘ï¼‰ï¼š\nå¯ä¿¡äººå·¥æ™ºèƒ½ï¼š AIGCå®‰å…¨ï¼Œå¤§æ¨¡å‹å®‰å…¨ã€AIç®—æ³•åˆè§„æ€§ è‡ªç„¶è¯­è¨€å¤„ç†ï¼šç¤¾äº¤åª’ä½“å†…å®¹å®‰å…¨ã€çŸ¥è¯†æ¨ç† æ™ºèƒ½ä¿¡æ¯æ£€ç´¢ï¼šå¯ä¿¡æ¨èç³»ç»Ÿã€æ¨èæ™ºèƒ½ä½“ åšå£«åæ‹›è˜ï¼ˆé•¿æœŸæœ‰æ•ˆï¼‰ #ä»äº‹ç›¸å…³é¢†åŸŸç ”ç©¶ã€è‡´åŠ›äºä»äº‹é«˜è´¨é‡çš„å­¦æœ¯ç ”ç©¶ï¼›å·²ä»¥ç¬¬ä¸€ä½œè€…èº«ä»½åœ¨ç›¸å…³é¢†åŸŸå‘è¡¨é«˜è´¨é‡å­¦æœ¯è®ºæ–‡ç­‰ã€‚åšå£«åå¾…é‡é‡‡å–æ ¹æ®å…·ä½“æƒ…å†µç»™äºˆå®éªŒå®¤è¡¥è´´ã€åŒæ—¶æ¨èç”³è¯·å­¦æ ¡ã€æ·±åœ³ã€å¹¿ä¸œçœå„é¡¹è¡¥è´´ã€‚\nåšå£«æ‹›ç”Ÿè¦æ±‚ # å…·æœ‰ç§‘ç ”è‡ªé©±åŠ›ã€è¾ƒå¼ºçš„ç¼–ç¨‹èƒ½åŠ›ã€å‹¤å¥‹è®¤çœŸï¼Œå–œæ¬¢ç‹¬ç«‹æ€è€ƒï¼› è‡´åŠ›äºä»äº‹é«˜è´¨é‡çš„å­¦æœ¯ç ”ç©¶ï¼› ç¡•å£«ç ”ç©¶ç”Ÿç”³è¯·åšå£«éœ€è¦ä»¥ç¬¬ä¸€ä½œè€…èº«ä»½å‘è¡¨è¿‡ç›¸å…³æ–¹å‘çš„é«˜è´¨é‡å­¦æœ¯è®ºæ–‡æˆ–å…¶ä»–ç­‰åŒä¼˜åŠ¿ï¼› è‰¯å¥½çš„è‹±æ–‡å†™ä½œèƒ½åŠ›ã€‚ å®ä¹ ç”Ÿè¦æ±‚ # å·²å®ŒæˆåŸºç¡€è¯¾ç¨‹çš„åœ¨è¯»åšå£«ã€ç¡•å£«ç ”ç©¶ç”Ÿã€é«˜å¹´çº§æœ¬ç§‘ç”Ÿï¼› å…·æœ‰è‡ªé©±åŠ›ã€è¾ƒå¼ºçš„ç¼–ç¨‹èƒ½åŠ›ã€å‹¤å¥‹è®¤çœŸï¼› è‡´åŠ›äºä»äº‹é«˜è´¨é‡çš„å­¦æœ¯ç ”ç©¶æˆ–å®é™…åœºæ™¯é¡¹ç›®ï¼Œä¼˜å…ˆè€ƒè™‘å…·æœ‰ç§‘ç ”æˆæœä¸ç«èµ›ç»å†çš„åŒå­¦ï¼› å®ä¹ æœŸè‡³å°‘ 6 ä¸ªæœˆï¼ˆ10ä¸ªæœˆä¼˜å…ˆï¼‰ï¼Œå¹¶è·å¾—æ‰€åœ¨å­¦æ ¡å’ŒæŒ‡å¯¼è€å¸ˆçš„åŒæ„ï¼Œå®ä¹ æœŸé—´æœä»è¯¾é¢˜ç»„çš„è§„ç« åˆ¶åº¦ã€‚ ç”³è¯·æ–¹å¼ #æœ‰å…´è¶£çš„åŒå­¦è¯·å‘é€ç®€å†ã€æˆç»©å•ã€ä»£è¡¨æ€§è®ºæ–‡æˆ–é¡¹ç›®åˆ°é‚®ç®±ï¼šlvzy7@mail.sysu.edu.cn\né‚®ä»¶æ ¼å¼ä¸ºï¼š\u0026ldquo;Year-Position-Your Name-Your affiliation\u0026rdquo;\nä¾‹å¦‚ï¼š25-PhD-Li Ming-SYSU\n","date":"January 1 0001","permalink":"http://localhost:1313/recruitment/","section":"","summary":"\u003cp\u003eä¸­å±±å¤§å­¦ç½‘ç»œç©ºé—´å®‰å…¨å­¦é™¢ï¼ˆåœ°ç†ä½ç½®ï¼šæ·±åœ³æ ¡åŒºï¼‰å•å­é’°è¯¾é¢˜ç»„è¯šæ‹› 2026 ç§‹å­£å…¥å­¦åšå£«ç”Ÿ/ç¡•å£«ç”Ÿï¼Œé•¿æœŸæ‹›è˜åšå£«åå’Œå®ä¹ ç”Ÿï¼Œæœ‰æ„å‘ç”³è¯·2027 ç§‹å­£çš„åŒå­¦ï¼ˆç‰¹åˆ«æœ‰æ„ä¿ç ”çš„åŒå­¦ï¼‰ä¹Ÿå¯ä»¥è”ç³»æˆ–è€…å…ˆç”³è¯·å®ä¹ ç”Ÿã€‚è¯¾é¢˜ç»„å­¦æœ¯æ°›å›´æµ“åšã€æ¯å‘¨è‡³å°‘ä¸€æ¬¡1å¯¹1çš„å¯¼å¸ˆäº¤æµæŒ‡å¯¼ã€‚ä¼˜ç§€çš„å­¦ç”Ÿã€åšå£«åå¯ä»¥æ¨èåˆ°å›½å†…å¤–è‘—åé«˜æ ¡å’Œå›½å†…çŸ¥åç§‘æŠ€å…¬å¸äº¤æµã€è®¿å­¦ã€å®ä¹ ç­‰ã€‚\u003c/p\u003e\n\u003ch2 id=\"ç ”ç©¶æ–¹å‘\" class=\"relative group\"\u003eç ”ç©¶æ–¹å‘ \u003cspan class=\"absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100\"\u003e\u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\" style=\"text-decoration-line: none !important;\" href=\"#%e7%a0%94%e7%a9%b6%e6%96%b9%e5%90%91\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\u003c/span\u003e\u003c/h2\u003e\u003cp\u003eå…·ä½“ç ”ç©¶æ–¹å‘å¦‚ä¸‹ï¼ˆä¸ä»…é™äºä»¥ä¸‹æ–¹å‘ï¼‰ï¼š\u003c/p\u003e","title":"æ‹›è˜ä¿¡æ¯"}]