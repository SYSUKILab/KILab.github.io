






<!doctype html>
<html
  lang="en"
  dir="ltr"
  class="scroll-smooth"
  data-default-appearance="light"
  data-auto-appearance="true"
><head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <meta name="theme-color" content="#FFFFFF" />
  
  <title>D-Judge: How Far Are We? Accessing the Discrepancies Between AI-synthesized Images and Natural Images through Multimodal Guidance &middot; KILab🚀</title>
    <meta name="title" content="D-Judge: How Far Are We? Accessing the Discrepancies Between AI-synthesized Images and Natural Images through Multimodal Guidance &middot; KILab🚀" />
  
  
  
  
  
  <script
    type="text/javascript"
    src="http://localhost:1313/js/appearance.min.8a082f81b27f3cb2ee528df0b0bdc39787034cf2cc34d4669fbc9977c929023c.js"
    integrity="sha256-iggvgbJ/PLLuUo3wsL3Dl4cDTPLMNNRmn7yZd8kpAjw="
  ></script>
  
  
  
  
  
  
  
  
  <link
    type="text/css"
    rel="stylesheet"
    href="http://localhost:1313/css/main.bundle.min.0fc2ef930d53c70c53effb01f12118005a26719d9223a1599730c1d26ee3f132.css"
    integrity="sha256-D8Lvkw1TxwxT7/sB8SEYAFomcZ2SI6FZlzDB0m7j8TI="
  />
  
    
    
    
  
  
  
    
    
  
  
  
  
    
    <script
      defer
      type="text/javascript"
      id="script-bundle"
      src="http://localhost:1313/js/main.bundle.min.0b250a079f6c2f7d0e03d1f0aa1308acb88137e3caebe1268f7478f0c87c5bf8.js"
      integrity="sha256-CyUKB59sL30OA9HwqhMIrLiBN&#43;PK6&#43;Emj3R48Mh8W/g="
      data-copy="Copy"
      data-copied="Copied"
    ></script>
  
  
  <meta
    name="description"
    content="
      
        AI-generated images are more visually stunning than ever, but how do they really stack up against natural, real-world photos? We introduce D-Judge, a large-scale benchmark designed to systematically investigate and quantify the discrepancies that remain.
      
    "
  />
  
  
  
  
    <link rel="canonical" href="http://localhost:1313/posts/djudge/" />
  
  
  
    <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png" />
    <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png" />
    <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png" />
    <link rel="manifest" href="/site.webmanifest" />
  
  
  
  
  
  
  
  
  <meta property="og:url" content="http://localhost:1313/posts/djudge/">
  <meta property="og:site_name" content="KILab🚀">
  <meta property="og:title" content="D-Judge: How Far Are We? Accessing the Discrepancies Between AI-synthesized Images and Natural Images through Multimodal Guidance">
  <meta property="og:description" content="AI-generated images are more visually stunning than ever, but how do they really stack up against natural, real-world photos? We introduce D-Judge, a large-scale benchmark designed to systematically investigate and quantify the discrepancies that remain.">
  <meta property="og:locale" content="en">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2025-07-30T00:00:00+00:00">
    <meta property="article:modified_time" content="2025-07-30T00:00:00+00:00">
    <meta property="og:image" content="http://localhost:1313/posts/djudge/feature.png">

  
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:image" content="http://localhost:1313/posts/djudge/feature.png">
  <meta name="twitter:title" content="D-Judge: How Far Are We? Accessing the Discrepancies Between AI-synthesized Images and Natural Images through Multimodal Guidance">
  <meta name="twitter:description" content="AI-generated images are more visually stunning than ever, but how do they really stack up against natural, real-world photos? We introduce D-Judge, a large-scale benchmark designed to systematically investigate and quantify the discrepancies that remain.">

  
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "Article",
    "articleSection": "",
    "name": "D-Judge: How Far Are We? Accessing the Discrepancies Between AI-synthesized Images and Natural Images through Multimodal Guidance",
    "headline": "D-Judge: How Far Are We? Accessing the Discrepancies Between AI-synthesized Images and Natural Images through Multimodal Guidance",
    
    "abstract": "\u003cp\u003eAI-generated images are more visually stunning than ever, but how do they really stack up against natural, real-world photos? We introduce D-Judge, a large-scale benchmark designed to systematically investigate and quantify the discrepancies that remain.\u003c\/p\u003e",
    "inLanguage": "en",
    "url" : "http:\/\/localhost:1313\/posts\/djudge\/",
    "author" : {
      "@type": "Person",
      "name": "KILab"
    },
    "copyrightYear": "2025",
    "dateCreated": "2025-07-30T00:00:00\u002b00:00",
    "datePublished": "2025-07-30T00:00:00\u002b00:00",
    
    "dateModified": "2025-07-30T00:00:00\u002b00:00",
    
    
    
    "mainEntityOfPage": "true",
    "wordCount": "954"
  }
  </script>
    
    <script type="application/ld+json">
    {
   "@context": "https://schema.org",
   "@type": "BreadcrumbList",
   "itemListElement": [
     {
       "@type": "ListItem",
       "item": "http://localhost:1313/",
       "name": "",
       "position": 1
     },
     {
       "@type": "ListItem",
       "item": "http://localhost:1313/posts/",
       "name": "",
       "position": 2
     },
     {
       "@type": "ListItem",
       "name": "D Judge How Far Are We? Accessing the Discrepancies Between Ai Synthesized Images and Natural Images Through Multimodal Guidance",
       "position": 3
     }
   ]
 }
  </script>

  
  
    <meta name="author" content="KILab" />
  
  
  
  







  
  

  
  
</head>
<body
    class="m-auto flex h-screen max-w-7xl flex-col bg-neutral px-6 text-lg leading-7 text-neutral-900 dark:bg-neutral-800 dark:text-neutral sm:px-14 md:px-24 lg:px-32"
  >
    <div id="the-top" class="absolute flex self-center">
      <a
        class="-translate-y-8 rounded-b-lg bg-primary-200 px-3 py-1 text-sm focus:translate-y-0 dark:bg-neutral-600"
        href="#main-content"
        ><span class="pe-2 font-bold text-primary-600 dark:text-primary-400">&darr;</span
        >Skip to main content</a
      >
    </div>
    
    
      <header class="py-6 font-semibold text-neutral-900 dark:text-neutral sm:py-10 print:hidden">
  <nav class="flex items-start justify-between sm:items-center">
    
    <div class="flex flex-row items-center">
      
  <a
    class="decoration-primary-500 hover:underline hover:decoration-2 hover:underline-offset-2"
    rel="me"
    href="/"
    >KILab🚀</a
  >

    </div>
    
    
      <ul class="flex list-none flex-col text-end sm:flex-row">
        
          
            
            <li class="group mb-1 sm:mb-0 sm:me-7 sm:last:me-0.5">
              
                <a
                  href="/"
                  title=""
                  
                  ><span
                      class="decoration-primary-500 group-hover:underline group-hover:decoration-2 group-hover:underline-offset-2"
                      >Home</span
                    >
                  </a
                >
              
            </li>
          
            
            <li class="group mb-1 sm:mb-0 sm:me-7 sm:last:me-0.5">
              
                <a
                  href="/posts/"
                  title=""
                  
                  ><span
                      class="decoration-primary-500 group-hover:underline group-hover:decoration-2 group-hover:underline-offset-2"
                      >News</span
                    >
                  </a
                >
              
            </li>
          
            
            <li class="group mb-1 sm:mb-0 sm:me-7 sm:last:me-0.5">
              
                <a
                  href="/publications/"
                  title="SELECTED PUBLICATIONS"
                  
                  ><span
                      class="decoration-primary-500 group-hover:underline group-hover:decoration-2 group-hover:underline-offset-2"
                      >Publications</span
                    >
                  </a
                >
              
            </li>
          
            
            <li class="group mb-1 sm:mb-0 sm:me-7 sm:last:me-0.5">
              
                <a
                  href="/recruitment/"
                  title="招聘信息"
                  
                  ><span
                      class="decoration-primary-500 group-hover:underline group-hover:decoration-2 group-hover:underline-offset-2"
                      >Recruitment</span
                    >
                  </a
                >
              
            </li>
          
            
            <li class="group mb-1 sm:mb-0 sm:me-7 sm:last:me-0.5">
              
                <a
                  href="/team/"
                  title="Team Members"
                  
                  ><span
                      class="decoration-primary-500 group-hover:underline group-hover:decoration-2 group-hover:underline-offset-2"
                      >Team</span
                    >
                  </a
                >
              
            </li>
          
            
            <li class="group mb-1 sm:mb-0 sm:me-7 sm:last:me-0.5">
              
                
                
                  <button
                    id="search-button-1"
                    title="Search (/)"
                  >
                    
                      <span
                        class="group-dark:hover:text-primary-400 transition-colors group-hover:text-primary-600"
                      ><span class="icon relative inline-block px-1 align-text-bottom"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M505 442.7L405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9 0 208 0S0 93.1 0 208s93.1 208 208 208c48.3 0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9 0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7 0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7 0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg>
</span></span><span
                        class="decoration-primary-500 group-hover:underline group-hover:decoration-2 group-hover:underline-offset-2"
                        ></span
                      >
                    
                  </button>
                
              
            </li>
          
            
              
          
        
      </ul>
    
  </nav>
</header>

    
    <div class="relative flex grow flex-col">
      <main id="main-content" class="grow">
        
  <article>
    <header class="max-w-prose">
      
      <h1 class="mb-8 mt-0 text-4xl font-extrabold text-neutral-900 dark:text-neutral">
        D-Judge: How Far Are We? Accessing the Discrepancies Between AI-synthesized Images and Natural Images through Multimodal Guidance
      </h1>
      
        <div class="mb-10 text-base text-neutral-500 dark:text-neutral-400 print:hidden">
          





  
  



  

  
  
    
  

  

  

  

  


  <div class="flex flex-row flex-wrap items-center">
    
    
      <time datetime="2025-07-30 00:00:00 &#43;0000 UTC">July 30 2025</time>
    

    
    
  </div>

  
  


        </div>
      
      
        <div class="prose">
          
          
          
          








  
    <picture
      class="mb-6 rounded-md"
      
    >
      
      
      
      
        <source
          
            srcset="http://localhost:1313/posts/djudge/feature_hu_8f2a85109222c184.webp 330w,http://localhost:1313/posts/djudge/feature_hu_3c8c6fabbbc4faef.webp 660w
            
              ,http://localhost:1313/posts/djudge/feature_hu_76ab6c4f9776138f.webp 1024w
            
            
              ,http://localhost:1313/posts/djudge/feature_hu_f24285a555a5e4a0.webp 1320w
            "
          
          sizes="100vw"
          type="image/webp"
        />
      
      <img
        width="3064"
        height="1186"
        class="mb-6 rounded-md"
        
        
        
          src="http://localhost:1313/posts/djudge/feature_hu_faa13a251d42a23f.png" srcset="http://localhost:1313/posts/djudge/feature_hu_23519f3a6d730d7b.png 330w,http://localhost:1313/posts/djudge/feature_hu_faa13a251d42a23f.png 660w
          
            ,http://localhost:1313/posts/djudge/feature_hu_98b8db9b1db173c.png 1024w
          
          
            ,http://localhost:1313/posts/djudge/feature_hu_238be55adee6fabf.png 1320w
          "
          sizes="100vw"
        
      />
    </picture>
  


          
        </div>
      
    </header>
    <section class="prose mt-0 flex max-w-full flex-col dark:prose-invert lg:flex-row">
      
      <div class="min-h-0 min-w-0 max-w-prose grow">
        <p>AI-generated images are more visually stunning than ever, but how do they really stack up against natural, real-world photos? We introduce D-Judge, a large-scale benchmark designed to systematically investigate and quantify the discrepancies that remain.</p>
<p>Despite the rapid progress of generative models, AI-generated images (AIGIs) often fall short of real-world application standards. Existing evaluation methods provide an incomplete picture. They often focus on a narrow set of metrics like perceptual quality or text alignment, use small datasets, and primarily consider simple text-to-image prompts, neglecting more complex multimodal guidance.</p>
<div class="flex rounded-md bg-primary-100 px-4 py-3 dark:bg-primary-900">
  <span class="pe-3 text-primary-400">
    <span class="icon relative inline-block px-1 align-text-bottom"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M506.3 417l-213.3-364c-16.33-28-57.54-28-73.98 0l-213.2 364C-10.59 444.9 9.849 480 42.74 480h426.6C502.1 480 522.6 445 506.3 417zM232 168c0-13.25 10.75-24 24-24S280 154.8 280 168v128c0 13.25-10.75 24-23.1 24S232 309.3 232 296V168zM256 416c-17.36 0-31.44-14.08-31.44-31.44c0-17.36 14.07-31.44 31.44-31.44s31.44 14.08 31.44 31.44C287.4 401.9 273.4 416 256 416z"/></svg>
</span>
  </span>
  <span class="dark:text-neutral-300">Key Problem: There&rsquo;s no systematic, comprehensive way to measure the fine-grained differences between AI-generated and natural images, which is crucial for understanding model limitations and driving meaningful progress.</span>
</div>

<p><a
  class="inline-block !rounded-md bg-primary-600 px-4 py-1 !text-neutral !no-underline hover:!bg-primary-500 dark:bg-primary-800 dark:hover:!bg-primary-700"
  href="https://arxiv.org/pdf/2412.17632"
  target="_blank"
  
  role="button"
>
  
📄 Paper

</a>

<a
  class="inline-block !rounded-md bg-primary-600 px-4 py-1 !text-neutral !no-underline hover:!bg-primary-500 dark:bg-primary-800 dark:hover:!bg-primary-700"
  href="https://github.com/ryliu68/DJudge"
  target="_blank"
  
  role="button"
>
  
📁 Code

</a>

<a
  class="inline-block !rounded-md bg-primary-600 px-4 py-1 !text-neutral !no-underline hover:!bg-primary-500 dark:bg-primary-800 dark:hover:!bg-primary-700"
  href="https://huggingface.co/datasets/Renyang/DANI"
  target="_blank"
  
  role="button"
>
  
🤗 Dataset

</a>
</p>
<p>Our work introduces two core contributions to tackle this challenge:</p>
<p>The D-ANI Dataset: A massive new multimodal dataset featuring over 440,000 AI-generated images from 9 representative models (from GANs to DALL-E 3). It&rsquo;s the first to include images generated from unimodal (Text-to-Image, Image-to-Image) and multimodal (Text-and-Image-to-Image) prompts.</p>
<p>The D-Judge Framework: A fine-grained evaluation framework that assesses discrepancies across five crucial dimensions: naive visual quality, semantic alignment, aesthetic appeal, downstream task applicability, and coordinated human validation.</p>
<p>Method &amp; System</p>
<ol>
<li>Framework Overview
D-Judge systematically compares AI-generated images with their natural counterparts. For a given prompt, we generate an AIGI and pair it with a real reference image. The framework then assesses the &ldquo;Discrepancy Rate&rdquo; (DR) between the two across our five dimensions, integrating both automated metrics and human judgment for a holistic view.</li>
</ol>

  
  
  
  
  

  
  
  <figure class="mx-auto my-0 rounded-md">
    
      
      








  
    <picture
      class="mx-auto my-0 rounded-md"
      
    >
      
      
      
      
        <source
          
            srcset="http://localhost:1313/posts/djudge/feature_hu_8f2a85109222c184.webp 330w,http://localhost:1313/posts/djudge/feature_hu_3c8c6fabbbc4faef.webp 660w
            
              ,http://localhost:1313/posts/djudge/feature_hu_76ab6c4f9776138f.webp 1024w
            
            
              ,http://localhost:1313/posts/djudge/feature_hu_f24285a555a5e4a0.webp 1320w
            "
          
          sizes="100vw"
          type="image/webp"
        />
      
      <img
        width="3064"
        height="1186"
        class="mx-auto my-0 rounded-md"
        alt="D-Judge Framework"
        loading="lazy" decoding="async"
        
          src="http://localhost:1313/posts/djudge/feature_hu_faa13a251d42a23f.png" srcset="http://localhost:1313/posts/djudge/feature_hu_23519f3a6d730d7b.png 330w,http://localhost:1313/posts/djudge/feature_hu_faa13a251d42a23f.png 660w
          
            ,http://localhost:1313/posts/djudge/feature_hu_98b8db9b1db173c.png 1024w
          
          
            ,http://localhost:1313/posts/djudge/feature_hu_238be55adee6fabf.png 1320w
          "
          sizes="100vw"
        
      />
    </picture>
  


    <figcaption class="text-center">Figure 1. The D-Judge framework evaluates discrepancies across five dimensions, complemented by human validation.</figcaption>
  </figure>


<ol start="2">
<li>The D-ANI Dataset
<span class="flex">
  <span
    class="ms-1 rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400"
  >
    Our Massive Dataset
  </span>
</span>

</li>
</ol>
<p>At the heart of our benchmark is the D-ANI (Distinguishing Natural and AI-generated) dataset. We started with 5,000 high-quality natural images from the MS COCO dataset, each with at least five captions. We then used these text-image pairs to prompt nine different generative models to create a diverse collection of over 440,000 AIGIs.</p>
<p>Models: Includes GANs (GALIP, DF-GAN), various Stable Diffusion versions (v1.4, v1.5, v2.1, XL), Versatile Diffusion, and OpenAI&rsquo;s DALL-E 2 &amp; 3.</p>
<p>Prompts: Uniquely covers Text-to-Image (T2I), Image-to-Image (I2I), and Text-and-Image-to-Image (TI2I) guidance.</p>

  
  
  
  
  

  
  
  <figure class="mx-auto my-0 rounded-md">
    
      
      








  
    <picture
      class="mx-auto my-0 rounded-md"
      
    >
      
      
      
      
        <source
          
            srcset="http://localhost:1313/posts/djudge/dataset_hu_dd66b967167b2d6c.webp 330w,http://localhost:1313/posts/djudge/dataset_hu_3baabf1d24f23d87.webp 660w
            
              ,http://localhost:1313/posts/djudge/dataset_hu_cc30ad64720c3c01.webp 1024w
            
            
              ,http://localhost:1313/posts/djudge/dataset_hu_58f96f9065691657.webp 1320w
            "
          
          sizes="100vw"
          type="image/webp"
        />
      
      <img
        width="2000"
        height="1106"
        class="mx-auto my-0 rounded-md"
        alt="D-ANI Dataset Creation"
        loading="lazy" decoding="async"
        
          src="http://localhost:1313/posts/djudge/dataset_hu_13b72fae7c044474.png" srcset="http://localhost:1313/posts/djudge/dataset_hu_87acf833389d6073.png 330w,http://localhost:1313/posts/djudge/dataset_hu_13b72fae7c044474.png 660w
          
            ,http://localhost:1313/posts/djudge/dataset_hu_887c9472889446ba.png 1024w
          
          
            ,http://localhost:1313/posts/djudge/dataset_hu_fc23b07c985f2ce8.png 1320w
          "
          sizes="100vw"
        
      />
    </picture>
  


    <figcaption class="text-center">Figure 2. Our D-ANI dataset includes 440,000+ images from 9 models, guided by three types of prompts.</figcaption>
  </figure>


<ol start="3">
<li>The 5-Dimension Evaluation
<span class="flex">
  <span
    class="ms-1 rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400"
  >
    Our Evaluation Framework
  </span>
</span>

</li>
</ol>
<p>D-Judge assesses the gap between AI and reality from five perspectives:</p>
<p>Naive Image Quality: How good is the image on a technical level? We measure this at three granularities:</p>
<p>Structure-level: Low-level visual similarity using metrics like SSIM and LPIPS.</p>
<p>Frame-level: Perceptual quality from a high-level view using metrics like BRISQUE and PIQE.</p>
<p>Distribution-level: Holistic content differences across the entire dataset using FID and Inception Score.</p>
<p>Semantic Alignment: Does the image match the prompt? We use CLIP Score to measure the consistency between the generated image and the guiding prompt(s).</p>
<p>Aesthetic Appeal: Is the image visually pleasing? We use models like NIMA and LAION-AES to predict the artistic quality and attractiveness.</p>
<p>Downstream Applicability: Can the image be used in other AI tasks? We test its utility in</p>
<p>image recognition, object segmentation, and Visual Question Answering (VQA).</p>
<p>Human Validation: How do people perceive these images? We collect human ratings on quality, alignment, and aesthetics to see if quantitative metrics align with human judgment.</p>
<p>Representative Findings
Our extensive experiments reveal that while AIGIs are impressive, significant gaps remain.</p>
<p>Key Discrepancies Revealed</p>
<p>Large Gaps Persist: AIGIs show substantial discrepancies from natural images, with difference rates of up to 40% in image quality, 33.57% in semantic alignment, and a staggering 96.95% in downstream task applicability (specifically VQA).</p>
<p>Downstream Tasks Suffer: The poor performance in downstream tasks like fine-grained object recognition and VQA highlights that current models struggle with practical, real-world utility.</p>
<p>Text Guidance is Key: Images generated with text prompts (T2I and TI2I) show much better semantic alignment than those generated from an image prompt alone (I2I).</p>
<p>Human vs. Machine Evaluation 🧐
<div class="flex rounded-md bg-primary-100 px-4 py-3 dark:bg-primary-900">
  <span class="pe-3 text-primary-400">
    <span class="icon relative inline-block px-1 align-text-bottom"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path fill="currentColor" d="M112.1 454.3c0 6.297 1.816 12.44 5.284 17.69l17.14 25.69c5.25 7.875 17.17 14.28 26.64 14.28h61.67c9.438 0 21.36-6.401 26.61-14.28l17.08-25.68c2.938-4.438 5.348-12.37 5.348-17.7L272 415.1h-160L112.1 454.3zM191.4 .0132C89.44 .3257 16 82.97 16 175.1c0 44.38 16.44 84.84 43.56 115.8c16.53 18.84 42.34 58.23 52.22 91.45c.0313 .25 .0938 .5166 .125 .7823h160.2c.0313-.2656 .0938-.5166 .125-.7823c9.875-33.22 35.69-72.61 52.22-91.45C351.6 260.8 368 220.4 368 175.1C368 78.61 288.9-.2837 191.4 .0132zM192 96.01c-44.13 0-80 35.89-80 79.1C112 184.8 104.8 192 96 192S80 184.8 80 176c0-61.76 50.25-111.1 112-111.1c8.844 0 16 7.159 16 16S200.8 96.01 192 96.01z"/></svg>
</span>
  </span>
  <span class="dark:text-neutral-300">Key Finding: Human evaluators consistently identify larger discrepancies in quality, alignment, and aesthetics than our automated metrics do. This shows that current metrics don&rsquo;t fully capture human perception and validates the need for human-in-the-loop evaluation.</span>
</div>
</p>
<p>Category Matters: The gap between AI and natural images varies significantly across different content categories (e.g., &ldquo;animal&rdquo; vs. &ldquo;accessory&rdquo;), likely due to imbalances in training data. DALL-E 3, for instance, showed the most pronounced deviations, possibly due to its tendency to generate more stylized imagery.</p>
<p>How to Use D-Judge
Our benchmark is a resource for the community to drive AIGC research forward.</p>
<p>For Researchers &amp; Developers
Evaluate New Models: Use the D-ANI dataset and the D-Judge framework to rigorously benchmark new generative models against a diverse set of conditions.</p>
<p>Identify Weaknesses: The five-dimensional analysis helps pinpoint specific areas where a model is underperforming (e.g., poor structural fidelity, weak semantic alignment on I2I tasks).</p>
<p>Develop Better Models: Beyond evaluation, D-Judge can serve as a training signal—for instance, as a reward function in reinforcement learning—to optimize models for better alignment and usability.</p>
<p>Acknowledgments
<div class="flex rounded-md bg-primary-100 px-4 py-3 dark:bg-primary-900">
  <span class="pe-3 text-primary-400">
    
  </span>
  <span class="dark:text-neutral-300">Acknowledgments: This work is supported by Guangdong Basic and Applied Basic Research Foundation (2023A1515012848), CCF-DiDi GAIA Collaborative Research Funds, A*STAR, CISCO Systems (USA) Pte.Ltd, and the National University of Singapore. We thank all the volunteers who participated in our human evaluation experiments.</span>
</div>
</p>
<p>Citation
Reference (ACM MM &lsquo;25, Dublin, Ireland):</p>
<p>Renyang Liu, Ziyu Lyu, Wei Zhou, and See-Kiong Ng. 2025. D-Judge: How Far Are We? Assessing the Discrepancies Between AI-synthesized and Natural Images through Multimodal Guidance. In Proceedings of the 33rd ACM International Conference on Multimedia (MM &lsquo;25). ACM, New York, NY, USA, 19 pages. <a href="https://arxiv.org/pdf/2412.17632" target="_blank" rel="noreferrer">https://arxiv.org/pdf/2412.17632</a></p>
<details>
<summary>BibTeX</summary>
@article{liu2024d,
  title={D-Judge: How Far Are We? Evaluating the Discrepancies Between AI-synthesized Images and Natural Images through Multimodal Guidance},
  author={Liu, Renyang and Lyu, Ziyu and Zhou, Wei and Ng, See-Kiong},
  journal={arXiv preprint arXiv:2412.17632},
  year={2024}
}
</details>
      </div>
    </section>
    <footer class="max-w-prose pt-8 print:hidden">
      

      

      
  
    
    
    
    <div class="pt-8">
      <hr class="border-dotted border-neutral-300 dark:border-neutral-600" />
      <div class="flex justify-between pt-3">
        <span>
          
            <a class="group flex" href="http://localhost:1313/posts/website-launch/">
              <span
                class="me-2 text-neutral-700 transition-transform group-hover:-translate-x-[2px] group-hover:text-primary-600 dark:text-neutral dark:group-hover:text-primary-400"
                ><span class="ltr:inline rtl:hidden">&larr;</span
                ><span class="ltr:hidden rtl:inline">&rarr;</span></span
              >
              <span class="flex flex-col">
                <span
                  class="mt-[0.1rem] leading-6 group-hover:underline group-hover:decoration-primary-500"
                  >🎊 Official Lab Website Launched</span
                >
                <span class="mt-[0.1rem] text-xs text-neutral-500 dark:text-neutral-400">
                  
                    <time datetime="2025-01-01 00:00:00 &#43;0000 UTC">January 1 2025</time>
                  
                </span>
              </span>
            </a>
          
        </span>
        <span>
          
        </span>
      </div>
    </div>
  


      
    </footer>
  </article>

      </main>
      
        <div
          class="pointer-events-none absolute bottom-0 end-0 top-[100vh] w-12"
          id="to-top"
          hidden="true"
        >
          <a
            href="#the-top"
            class="pointer-events-auto sticky top-[calc(100vh-5.5rem)] flex h-12 w-12 items-center justify-center rounded-full bg-neutral/50 text-xl text-neutral-700 backdrop-blur hover:text-primary-600 dark:bg-neutral-800/50 dark:text-neutral dark:hover:text-primary-400"
            aria-label="Scroll to top"
            title="Scroll to top"
          >
            &uarr;
          </a>
        </div>
      <footer class="py-10 print:hidden">
  
  
    <nav class="pb-4 text-base font-medium text-neutral-500 dark:text-neutral-400">
      <ul class="flex list-none flex-col sm:flex-row">
        
          
          <li class="group mb-1 text-end sm:mb-0 sm:me-7 sm:last:me-0">
            
              <a
                href="/activities/"
                title="Lab Activities"
                
                ><span
                    class="decoration-primary-500 group-hover:underline group-hover:decoration-2 group-hover:underline-offset-2"
                    >Lab Activities</span
                  >
                </a
              >
            
          </li>
        
          
          <li class="group mb-1 text-end sm:mb-0 sm:me-7 sm:last:me-0">
            
              <a
                href="/conference_deadlines/"
                title="Conference Deadlines"
                
                ><span
                    class="decoration-primary-500 group-hover:underline group-hover:decoration-2 group-hover:underline-offset-2"
                    >Conference Deadlines</span
                  >
                </a
              >
            
          </li>
        
      </ul>
    </nav>
  
  <div class="flex items-center justify-between">
    <div>
      
      
        <p class="text-sm text-neutral-500 dark:text-neutral-400">
            <p><strong>Address</strong>: Room 910D, Engineering Building No.2, Shenzhen Campus of Sun Yat-sen University, No.66 Gongchang Road, Guangming District, Shenzhen, 518107, P. R. China</p>
<p><strong>Contact</strong>: <a href="mailto:lvzy7@mail.sysu.edu.cn">lvzy7@mail.sysu.edu.cn</a></p>
<p>© 2025 Knowledge Intelligince Lab @ SYSU.</p>

        </p>
      
      
      
        <p class="text-xs text-neutral-500 dark:text-neutral-400">
          
          
          Powered by <a class="hover:underline hover:decoration-primary-400 hover:text-primary-500"
            href="https://gohugo.io/" target="_blank" rel="noopener noreferrer">Hugo</a> &amp; <a class="hover:underline hover:decoration-primary-400 hover:text-primary-500" href="https://github.com/jpanther/congo" target="_blank" rel="noopener noreferrer">Congo</a>
        </p>
      
    </div>
    <div class="flex flex-row items-center">
      
      
      
      
    </div>
  </div>
  
  
</footer>
<div
  id="search-wrapper"
  class="invisible fixed inset-0 z-50 flex h-screen w-screen cursor-default flex-col bg-neutral-500/50 p-4 backdrop-blur-sm dark:bg-neutral-900/50 sm:p-6 md:p-[10vh] lg:p-[12vh]"
  data-url="http://localhost:1313/"
>
  <div
    id="search-modal"
    class="top-20 mx-auto flex min-h-0 w-full max-w-3xl flex-col rounded-md border border-neutral-200 bg-neutral shadow-lg dark:border-neutral-700 dark:bg-neutral-800"
  >
    <header class="relative z-10 flex flex-none items-center justify-between px-2">
      <form class="flex min-w-0 flex-auto items-center">
        <div class="flex h-8 w-8 items-center justify-center text-neutral-400">
          <span class="icon relative inline-block px-1 align-text-bottom"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M505 442.7L405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9 0 208 0S0 93.1 0 208s93.1 208 208 208c48.3 0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9 0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7 0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7 0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg>
</span>
        </div>
        <input
          type="search"
          id="search-query"
          class="mx-1 flex h-12 flex-auto appearance-none bg-transparent focus:outline-dotted focus:outline-2 focus:outline-transparent"
          placeholder="Search"
          tabindex="0"
        />
      </form>
      <button
        id="close-search-button"
        class="flex h-8 w-8 items-center justify-center text-neutral-700 hover:text-primary-600 dark:text-neutral dark:hover:text-primary-400"
        title="Close (Esc)"
      >
        <span class="icon relative inline-block px-1 align-text-bottom"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><path fill="currentColor" d="M310.6 361.4c12.5 12.5 12.5 32.75 0 45.25C304.4 412.9 296.2 416 288 416s-16.38-3.125-22.62-9.375L160 301.3L54.63 406.6C48.38 412.9 40.19 416 32 416S15.63 412.9 9.375 406.6c-12.5-12.5-12.5-32.75 0-45.25l105.4-105.4L9.375 150.6c-12.5-12.5-12.5-32.75 0-45.25s32.75-12.5 45.25 0L160 210.8l105.4-105.4c12.5-12.5 32.75-12.5 45.25 0s12.5 32.75 0 45.25l-105.4 105.4L310.6 361.4z"/></svg>
</span>
      </button>
    </header>
    <section class="flex-auto overflow-auto px-2">
      <ul id="search-results">
        
      </ul>
    </section>
  </div>
</div>

    </div>
  </body>
</html>
