






<!doctype html>
<html
  lang="en"
  dir="ltr"
  class="scroll-smooth"
  data-default-appearance="light"
  data-auto-appearance="true"
><head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <meta name="theme-color" content="#FFFFFF" />
  
  <title>MidPO: Dual Preference Optimization for Safety and Helpfulness in Large Language Models via a Mixture of Experts Framework &middot; KILab🚀</title>
    <meta name="title" content="MidPO: Dual Preference Optimization for Safety and Helpfulness in Large Language Models via a Mixture of Experts Framework &middot; KILab🚀" />
  
  
  
  
  
  <script
    type="text/javascript"
    src="http://localhost:1313/js/appearance.min.8a082f81b27f3cb2ee528df0b0bdc39787034cf2cc34d4669fbc9977c929023c.js"
    integrity="sha256-iggvgbJ/PLLuUo3wsL3Dl4cDTPLMNNRmn7yZd8kpAjw="
  ></script>
  
  
  
  
  
  
  
  
  <link
    type="text/css"
    rel="stylesheet"
    href="http://localhost:1313/css/main.bundle.min.0fc2ef930d53c70c53effb01f12118005a26719d9223a1599730c1d26ee3f132.css"
    integrity="sha256-D8Lvkw1TxwxT7/sB8SEYAFomcZ2SI6FZlzDB0m7j8TI="
  />
  
    
    
    
  
  
  
    
    
  
  
  
  
    
    <script
      defer
      type="text/javascript"
      id="script-bundle"
      src="http://localhost:1313/js/main.bundle.min.0b250a079f6c2f7d0e03d1f0aa1308acb88137e3caebe1268f7478f0c87c5bf8.js"
      integrity="sha256-CyUKB59sL30OA9HwqhMIrLiBN&#43;PK6&#43;Emj3R48Mh8W/g="
      data-copy="Copy"
      data-copied="Copied"
    ></script>
  
  
  <meta
    name="description"
    content="
      We introduce MidPO, a novel framework that uses specialized &#39;safety&#39; and &#39;helpfulness&#39; experts and a dynamic router to achieve a state-of-the-art balance between LLM safety and performance.
    "
  />
  
  
  
  
    <link rel="canonical" href="http://localhost:1313/posts/midpo/" />
  
  
  
    <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png" />
    <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png" />
    <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png" />
    <link rel="manifest" href="/site.webmanifest" />
  
  
  
  
  
  
  
  
  <meta property="og:url" content="http://localhost:1313/posts/midpo/">
  <meta property="og:site_name" content="KILab🚀">
  <meta property="og:title" content="MidPO: Dual Preference Optimization for Safety and Helpfulness in Large Language Models via a Mixture of Experts Framework">
  <meta property="og:description" content="We introduce MidPO, a novel framework that uses specialized &#39;safety&#39; and &#39;helpfulness&#39; experts and a dynamic router to achieve a state-of-the-art balance between LLM safety and performance.">
  <meta property="og:locale" content="en">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:tag" content="LLM">
    <meta property="article:tag" content="AI Safety">
    <meta property="article:tag" content="Preference Optimization">
    <meta property="article:tag" content="Mixture of Experts">
    <meta property="og:image" content="http://localhost:1313/posts/midpo/feature.png">

  
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:image" content="http://localhost:1313/posts/midpo/feature.png">
  <meta name="twitter:title" content="MidPO: Dual Preference Optimization for Safety and Helpfulness in Large Language Models via a Mixture of Experts Framework">
  <meta name="twitter:description" content="We introduce MidPO, a novel framework that uses specialized &#39;safety&#39; and &#39;helpfulness&#39; experts and a dynamic router to achieve a state-of-the-art balance between LLM safety and performance.">

  
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "Article",
    "articleSection": "",
    "name": "MidPO: Dual Preference Optimization for Safety and Helpfulness in Large Language Models via a Mixture of Experts Framework",
    "headline": "MidPO: Dual Preference Optimization for Safety and Helpfulness in Large Language Models via a Mixture of Experts Framework",
    "description": "We introduce MidPO, a novel framework that uses specialized \u0027safety\u0027 and \u0027helpfulness\u0027 experts and a dynamic router to achieve a state-of-the-art balance between LLM safety and performance.",
    "abstract": "\u003cp\u003eLarge Language Models (LLMs) need to be both helpful and safe, but achieving both is a major challenge. We propose MidPO, a Mixture of Experts (MoE) framework that fine-tunes two specialized experts for safety and helpfulness and uses a dynamic routing mechanism to adaptively balance them, outperforming existing methods.\u003c\/p\u003e",
    "inLanguage": "en",
    "url" : "http:\/\/localhost:1313\/posts\/midpo\/",
    "author" : {
      "@type": "Person",
      "name": "KILab"
    },
    
    
    
    
    
    
    "keywords": ["LLM","AI safety","preference optimization","mixture of experts"],
    
    "mainEntityOfPage": "true",
    "wordCount": "791"
  }
  </script>
    
    <script type="application/ld+json">
    {
   "@context": "https://schema.org",
   "@type": "BreadcrumbList",
   "itemListElement": [
     {
       "@type": "ListItem",
       "item": "http://localhost:1313/",
       "name": "",
       "position": 1
     },
     {
       "@type": "ListItem",
       "item": "http://localhost:1313/posts/",
       "name": "",
       "position": 2
     },
     {
       "@type": "ListItem",
       "item": "http://localhost:1313/categories/research/",
       "name": "Research",
       "position": 3
     },
     {
       "@type": "ListItem",
       "name": "Mid Po Dual Preference Optimization for Safety and Helpfulness in Large Language Models via a Mixture of Experts Framework",
       "position": 4
     }
   ]
 }
  </script>

  
  
    <meta name="author" content="KILab" />
  
  
  
  







  
  

  
  
</head>
<body
    class="m-auto flex h-screen max-w-7xl flex-col bg-neutral px-6 text-lg leading-7 text-neutral-900 dark:bg-neutral-800 dark:text-neutral sm:px-14 md:px-24 lg:px-32"
  >
    <div id="the-top" class="absolute flex self-center">
      <a
        class="-translate-y-8 rounded-b-lg bg-primary-200 px-3 py-1 text-sm focus:translate-y-0 dark:bg-neutral-600"
        href="#main-content"
        ><span class="pe-2 font-bold text-primary-600 dark:text-primary-400">&darr;</span
        >Skip to main content</a
      >
    </div>
    
    
      <header class="py-6 font-semibold text-neutral-900 dark:text-neutral sm:py-10 print:hidden">
  <nav class="flex items-start justify-between sm:items-center">
    
    <div class="flex flex-row items-center">
      
  <a
    class="decoration-primary-500 hover:underline hover:decoration-2 hover:underline-offset-2"
    rel="me"
    href="/"
    >KILab🚀</a
  >

    </div>
    
    
      <ul class="flex list-none flex-col text-end sm:flex-row">
        
          
            
            <li class="group mb-1 sm:mb-0 sm:me-7 sm:last:me-0.5">
              
                <a
                  href="/"
                  title=""
                  
                  ><span
                      class="decoration-primary-500 group-hover:underline group-hover:decoration-2 group-hover:underline-offset-2"
                      >Home</span
                    >
                  </a
                >
              
            </li>
          
            
            <li class="group mb-1 sm:mb-0 sm:me-7 sm:last:me-0.5">
              
                <a
                  href="/posts/"
                  title=""
                  
                  ><span
                      class="decoration-primary-500 group-hover:underline group-hover:decoration-2 group-hover:underline-offset-2"
                      >News</span
                    >
                  </a
                >
              
            </li>
          
            
            <li class="group mb-1 sm:mb-0 sm:me-7 sm:last:me-0.5">
              
                <a
                  href="/publications/"
                  title="SELECTED PUBLICATIONS"
                  
                  ><span
                      class="decoration-primary-500 group-hover:underline group-hover:decoration-2 group-hover:underline-offset-2"
                      >Publications</span
                    >
                  </a
                >
              
            </li>
          
            
            <li class="group mb-1 sm:mb-0 sm:me-7 sm:last:me-0.5">
              
                <a
                  href="/recruitment/"
                  title="招聘信息"
                  
                  ><span
                      class="decoration-primary-500 group-hover:underline group-hover:decoration-2 group-hover:underline-offset-2"
                      >Recruitment</span
                    >
                  </a
                >
              
            </li>
          
            
            <li class="group mb-1 sm:mb-0 sm:me-7 sm:last:me-0.5">
              
                <a
                  href="/team/"
                  title="Team Members"
                  
                  ><span
                      class="decoration-primary-500 group-hover:underline group-hover:decoration-2 group-hover:underline-offset-2"
                      >Team</span
                    >
                  </a
                >
              
            </li>
          
            
            <li class="group mb-1 sm:mb-0 sm:me-7 sm:last:me-0.5">
              
                
                
                  <button
                    id="search-button-1"
                    title="Search (/)"
                  >
                    
                      <span
                        class="group-dark:hover:text-primary-400 transition-colors group-hover:text-primary-600"
                      ><span class="icon relative inline-block px-1 align-text-bottom"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M505 442.7L405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9 0 208 0S0 93.1 0 208s93.1 208 208 208c48.3 0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9 0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7 0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7 0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg>
</span></span><span
                        class="decoration-primary-500 group-hover:underline group-hover:decoration-2 group-hover:underline-offset-2"
                        ></span
                      >
                    
                  </button>
                
              
            </li>
          
            
              
          
        
      </ul>
    
  </nav>
</header>

    
    <div class="relative flex grow flex-col">
      <main id="main-content" class="grow">
        
  <article class="max-w-full">
    <header>
      
      <h1 class="mt-0 text-4xl font-extrabold text-neutral-900 dark:text-neutral">
        MidPO: Dual Preference Optimization for Safety and Helpfulness in Large Language Models via a Mixture of Experts Framework
      </h1>
    </header>
    <section class="prose mt-6 max-w-full dark:prose-invert">
      <p>Large Language Models (LLMs) need to be both helpful and safe, but achieving both is a major challenge. We propose MidPO, a Mixture of Experts (MoE) framework that fine-tunes two specialized experts for safety and helpfulness and uses a dynamic routing mechanism to adaptively balance them, outperforming existing methods.</p>
<h2 id="the-safety-vs-helpfulness-dilemma" class="relative group">The Safety vs. Helpfulness Dilemma <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#the-safety-vs-helpfulness-dilemma" aria-label="Anchor">#</a></span></h2><p>Aligning Large Language Models (LLMs) is a delicate balancing act. Current methods often force a trade-off between being helpful and being safe.</p>
<ul>
<li>Online alignment methods (like RLHF) can be overly cautious, leading them to refuse safe, harmless prompts. This is known as the &ldquo;excessive safety&rdquo; or &ldquo;over-refusal&rdquo; problem.</li>
<li>Offline alignment methods (like DPO variants) often fail to adapt, sometimes providing helpful but harmful responses to unsafe prompts.</li>
</ul>
<div class="flex rounded-md bg-primary-100 px-4 py-3 dark:bg-primary-900">
  <span class="pe-3 text-primary-400">
    <span class="icon relative inline-block px-1 align-text-bottom"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M506.3 417l-213.3-364c-16.33-28-57.54-28-73.98 0l-213.2 364C-10.59 444.9 9.849 480 42.74 480h426.6C502.1 480 522.6 445 506.3 417zM232 168c0-13.25 10.75-24 24-24S280 154.8 280 168v128c0 13.25-10.75 24-23.1 24S232 309.3 232 296V168zM256 416c-17.36 0-31.44-14.08-31.44-31.44c0-17.36 14.07-31.44 31.44-31.44s31.44 14.08 31.44 31.44C287.4 401.9 273.4 416 256 416z"/></svg>
</span>
  </span>
  <span class="dark:text-neutral-300">Key Problem: Existing alignment techniques struggle to create LLMs that are both robustly safe against harmful queries and genuinely helpful for safe ones, often sacrificing one for the other.</span>
</div>

<p><a
  class="inline-block !rounded-md bg-primary-600 px-4 py-1 !text-neutral !no-underline hover:!bg-primary-500 dark:bg-primary-800 dark:hover:!bg-primary-700"
  href="https://arxiv.org/abs/2506.02460"
  target="_blank"
  
  role="button"
>
   📄 Paper 
</a>
 <a
  class="inline-block !rounded-md bg-primary-600 px-4 py-1 !text-neutral !no-underline hover:!bg-primary-500 dark:bg-primary-800 dark:hover:!bg-primary-700"
  
  
  
  role="button"
>
   📁 Code (to be released) 
</a>
</p>
<h2 id="what-we-built-the-midpo-framework" class="relative group">What We Built: The MidPO Framework <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#what-we-built-the-midpo-framework" aria-label="Anchor">#</a></span></h2><p>Our framework, MidPO (Mixture of Experts Dual Preference Optimization), addresses this challenge with two core components:</p>
<ul>
<li>Two Specialized Experts: Instead of a one-size-fits-all model, we train two distinct experts: a Safety Expert and a Helpfulness Expert. We use our novel Single-Preference Enhanced DPO (SPE-DPO) method to make each expert highly proficient in its domain.</li>
<li>A Dynamic Routing Mechanism: A smart &ldquo;router&rdquo; analyzes the user&rsquo;s prompt and adaptively decides how much to listen to the Safety Expert versus the Helpfulness Expert. This allows the model to be cautious with unsafe prompts but open and helpful with safe ones.</li>
<li>Efficient Offline Alignment: The entire framework is built on an offline alignment process, making it more stable and computationally efficient than online RLHF-based methods.</li>
</ul>
<h2 id="method--system" class="relative group">Method &amp; System <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#method--system" aria-label="Anchor">#</a></span></h2><ol>
<li>Framework Overview
MidPO first transforms a base LLM into two specialized experts using LoRA fine-tuning with our SPE-DPO loss functions. Then, it freezes the experts and trains a dynamic router that learns to combine their contributions effectively for any given prompt, achieving a superior balance between safety and helpfulness.</li>
</ol>

  
  
  
  
  

  
  
  <figure class="mx-auto my-0 rounded-md">
    
      
      








  
    <picture
      class="mx-auto my-0 rounded-md"
      
    >
      
      
      
      
        <source
          
            srcset="http://localhost:1313/posts/midpo/workflow_hu_8469c91a8a7c74b0.webp 330w,http://localhost:1313/posts/midpo/workflow_hu_45db87c313aa1e96.webp 660w
            
              ,http://localhost:1313/posts/midpo/workflow_hu_a0f503c445d90aad.webp 1024w
            
            
              ,http://localhost:1313/posts/midpo/workflow_hu_94aa8d6bcf7a2bd8.webp 1320w
            "
          
          sizes="100vw"
          type="image/webp"
        />
      
      <img
        width="1956"
        height="722"
        class="mx-auto my-0 rounded-md"
        alt="MidPO Framework overview"
        loading="lazy" decoding="async"
        
          src="http://localhost:1313/posts/midpo/workflow_hu_732b3a7c5eb18c80.png" srcset="http://localhost:1313/posts/midpo/workflow_hu_b609deeaf50b75c7.png 330w,http://localhost:1313/posts/midpo/workflow_hu_732b3a7c5eb18c80.png 660w
          
            ,http://localhost:1313/posts/midpo/workflow_hu_a1f152aa1a50b576.png 1024w
          
          
            ,http://localhost:1313/posts/midpo/workflow_hu_51dc3c38c818563e.png 1320w
          "
          sizes="100vw"
        
      />
    </picture>
  


    <figcaption class="text-center">Figure 1. The MidPO framework, showing (a) the training of single-preference experts and (b) the dynamic routing mechanism.</figcaption>
  </figure>


<ol start="2">
<li>Single-Preference Enhanced Experts (SPE-DPO)</li>
</ol>
<p>The foundation of MidPO is creating highly specialized experts. Our proposed SPE-DPO method is designed for single-preference optimization. By introducing a homogeneous preference margin, it amplifies the distinction between good and bad responses within a single category (e.g., safe vs. unsafe), making the experts more effective than if they were trained with standard DPO.</p>
<ol start="3">
<li>Dynamic Routing Mechanism</li>
</ol>
<p>This is where the magic happens. The router analyzes the input prompt and assigns a weight to the Safety and Helpfulness experts. For an unsafe question (e.g., &ldquo;How to do X illegal thing?&rdquo;), it gives more weight to the Safety Expert. For a safe question (e.g., &ldquo;How do I make my wife laugh?&rdquo;), it prioritizes the Helpfulness Expert. This adaptive approach ensures the final response is context-appropriately safe and helpful.</p>
<h2 id="data--settings" class="relative group">Data &amp; Settings <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#data--settings" aria-label="Anchor">#</a></span></h2><div class="flex rounded-md bg-primary-100 px-4 py-3 dark:bg-primary-900">
  <span class="pe-3 text-primary-400">
    <span class="icon relative inline-block px-1 align-text-bottom"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M256 0C114.6 0 0 114.6 0 256s114.6 256 256 256s256-114.6 256-256S397.4 0 256 0zM256 128c17.67 0 32 14.33 32 32c0 17.67-14.33 32-32 32S224 177.7 224 160C224 142.3 238.3 128 256 128zM296 384h-80C202.8 384 192 373.3 192 360s10.75-24 24-24h16v-64H224c-13.25 0-24-10.75-24-24S210.8 224 224 224h32c13.25 0 24 10.75 24 24v88h16c13.25 0 24 10.75 24 24S309.3 384 296 384z"/></svg>
</span>
  </span>
  <span class="dark:text-neutral-300"><p>Base Model: We built MidPO on top of the widely used Alpaca-7B model.</p>
<p>Datasets: We trained and evaluated MidPO on three popular benchmarks:</p>
<p><code>PKU-Safe RLHF</code> , <code>Do Not Answer</code> , and <code>Wildguard Mix</code>.</p>
</span>
</div>

<p>We compared MidPO against strong baselines, including</p>
<p>Safe RLHF (an online method) and MODPO (an offline method), ensuring a fair comparison by using the same base model for all methods where possible.</p>
<h2 id="representative-findings" class="relative group">Representative Findings <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#representative-findings" aria-label="Anchor">#</a></span></h2><p>Our comprehensive evaluation showed that MidPO sets a new standard for balancing safety and helpfulness.</p>
<p>Unprecedented Balance
MidPO consistently achieves the highest scores for both safety and helpfulness across all three datasets, significantly outperforming all baselines. Other methods either excel at one while failing at the other or are mediocre at both.</p>

  
  
  
  
  

  
  
  <figure class="mx-auto my-0 rounded-md">
    
      
      








  
    <picture
      class="mx-auto my-0 rounded-md"
      
    >
      
      
      
      
        <source
          
            srcset="http://localhost:1313/posts/midpo/compare_hu_1e10f9bdf0544994.webp 330w,http://localhost:1313/posts/midpo/compare_hu_2b392cce6f9805e7.webp 660w
            
              ,http://localhost:1313/posts/midpo/compare_hu_87ca6b98526b6022.webp 1024w
            
            
              ,http://localhost:1313/posts/midpo/compare_hu_1053eb2c1f74c428.webp 1320w
            "
          
          sizes="100vw"
          type="image/webp"
        />
      
      <img
        width="2770"
        height="1778"
        class="mx-auto my-0 rounded-md"
        alt="Safety vs. Helpfulness evaluation results"
        loading="lazy" decoding="async"
        
          src="http://localhost:1313/posts/midpo/compare_hu_9e0357139fd9f64e.png" srcset="http://localhost:1313/posts/midpo/compare_hu_10df4ee4a464a470.png 330w,http://localhost:1313/posts/midpo/compare_hu_9e0357139fd9f64e.png 660w
          
            ,http://localhost:1313/posts/midpo/compare_hu_ae0b83b9e1d38bd0.png 1024w
          
          
            ,http://localhost:1313/posts/midpo/compare_hu_76a687b0d02d23d5.png 1320w
          "
          sizes="100vw"
        
      />
    </picture>
  


    <figcaption class="text-center">Figure 2. MidPO (top right) achieves a superior balance of safety and helpfulness compared to baselines across three different datasets.</figcaption>
  </figure>


<h3 id="superior-experts-and-routing" class="relative group">Superior Experts and Routing <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#superior-experts-and-routing" aria-label="Anchor">#</a></span></h3><ul>
<li>
<p>Better Experts: Our experts, fine-tuned with SPE-DPO, demonstrated superior single-preference performance compared to experts trained with vanilla DPO.</p>
</li>
<li>
<p>Effective Routing: Ablation studies confirmed the crucial role of the dynamic routing mechanism. Removing it led to a significant drop in both safety (19.25% win rate) and helpfulness (13.62% win rate).</p>
</li>
</ul>
<div class="flex rounded-md bg-primary-100 px-4 py-3 dark:bg-primary-900">
  <span class="pe-3 text-primary-400">
    <span class="icon relative inline-block px-1 align-text-bottom"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path fill="currentColor" d="M112.1 454.3c0 6.297 1.816 12.44 5.284 17.69l17.14 25.69c5.25 7.875 17.17 14.28 26.64 14.28h61.67c9.438 0 21.36-6.401 26.61-14.28l17.08-25.68c2.938-4.438 5.348-12.37 5.348-17.7L272 415.1h-160L112.1 454.3zM191.4 .0132C89.44 .3257 16 82.97 16 175.1c0 44.38 16.44 84.84 43.56 115.8c16.53 18.84 42.34 58.23 52.22 91.45c.0313 .25 .0938 .5166 .125 .7823h160.2c.0313-.2656 .0938-.5166 .125-.7823c9.875-33.22 35.69-72.61 52.22-91.45C351.6 260.8 368 220.4 368 175.1C368 78.61 288.9-.2837 191.4 .0132zM192 96.01c-44.13 0-80 35.89-80 79.1C112 184.8 104.8 192 96 192S80 184.8 80 176c0-61.76 50.25-111.1 112-111.1c8.844 0 16 7.159 16 16S200.8 96.01 192 96.01z"/></svg>
</span>
  </span>
  <span class="dark:text-neutral-300">Key Finding: The combination of highly specialized experts and an adaptive routing mechanism allows MidPO to navigate the safety-helpfulness trade-off more effectively than any previous method.</span>
</div>

<h2 id="citation" class="relative group">Citation <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#citation" aria-label="Anchor">#</a></span></h2><p>Reference (arXiv Preprint):</p>
<p>Yupeng Qi, Ziyu Lyu, Min Yang, Yanlin Wang, Lu Bai, Lixin Cui. 2025. MidPO: Dual Preference Optimization for Safety and Helpfulness in Large Language Models via a Mixture of Experts Framework. arXiv preprint arXiv:2506.02460.</p>
<details>
<summary>BibTeX</summary>
<p>Code snippet</p>
<p>@misc{qi2025midpo,
title={MidPO: Dual Preference Optimization for Safety and Helpfulness in Large Language Models via a Mixture of Experts Framework},
author={Yupeng Qi and Ziyu Lyu and Min Yang and Yanlin Wang and Lu Bai and Lixin Cui},
year={2025},
eprint={2506.02460},
archivePrefix={arXiv},
primaryClass={cs.CL}
}</p>
</details>
    </section>
    <footer class="pt-8">
      

    </footer>
  </article>

      </main>
      
        <div
          class="pointer-events-none absolute bottom-0 end-0 top-[100vh] w-12"
          id="to-top"
          hidden="true"
        >
          <a
            href="#the-top"
            class="pointer-events-auto sticky top-[calc(100vh-5.5rem)] flex h-12 w-12 items-center justify-center rounded-full bg-neutral/50 text-xl text-neutral-700 backdrop-blur hover:text-primary-600 dark:bg-neutral-800/50 dark:text-neutral dark:hover:text-primary-400"
            aria-label="Scroll to top"
            title="Scroll to top"
          >
            &uarr;
          </a>
        </div>
      <footer class="py-10 print:hidden">
  
  
  <div class="flex items-center justify-between">
    <div>
      
      
        <p class="text-sm text-neutral-500 dark:text-neutral-400">
            <p><strong>Address</strong>: Room 910D, Engineering Building No.2, Shenzhen Campus of Sun Yat-sen University, No.66 Gongchang Road, Guangming District, Shenzhen, 518107, P. R. China</p>
<p><strong>Contact</strong>: <a href="mailto:lvzy7@mail.sysu.edu.cn">lvzy7@mail.sysu.edu.cn</a></p>
<p>© 2025 Knowledge Intelligince Lab @ SYSU.</p>

        </p>
      
      
      
        <p class="text-xs text-neutral-500 dark:text-neutral-400">
          
          
          Powered by <a class="hover:underline hover:decoration-primary-400 hover:text-primary-500"
            href="https://gohugo.io/" target="_blank" rel="noopener noreferrer">Hugo</a> &amp; <a class="hover:underline hover:decoration-primary-400 hover:text-primary-500" href="https://github.com/jpanther/congo" target="_blank" rel="noopener noreferrer">Congo</a>
        </p>
      
    </div>
    <div class="flex flex-row items-center">
      
      
      
      
    </div>
  </div>
  
  
</footer>
<div
  id="search-wrapper"
  class="invisible fixed inset-0 z-50 flex h-screen w-screen cursor-default flex-col bg-neutral-500/50 p-4 backdrop-blur-sm dark:bg-neutral-900/50 sm:p-6 md:p-[10vh] lg:p-[12vh]"
  data-url="http://localhost:1313/"
>
  <div
    id="search-modal"
    class="top-20 mx-auto flex min-h-0 w-full max-w-3xl flex-col rounded-md border border-neutral-200 bg-neutral shadow-lg dark:border-neutral-700 dark:bg-neutral-800"
  >
    <header class="relative z-10 flex flex-none items-center justify-between px-2">
      <form class="flex min-w-0 flex-auto items-center">
        <div class="flex h-8 w-8 items-center justify-center text-neutral-400">
          <span class="icon relative inline-block px-1 align-text-bottom"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M505 442.7L405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9 0 208 0S0 93.1 0 208s93.1 208 208 208c48.3 0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9 0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7 0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7 0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg>
</span>
        </div>
        <input
          type="search"
          id="search-query"
          class="mx-1 flex h-12 flex-auto appearance-none bg-transparent focus:outline-dotted focus:outline-2 focus:outline-transparent"
          placeholder="Search"
          tabindex="0"
        />
      </form>
      <button
        id="close-search-button"
        class="flex h-8 w-8 items-center justify-center text-neutral-700 hover:text-primary-600 dark:text-neutral dark:hover:text-primary-400"
        title="Close (Esc)"
      >
        <span class="icon relative inline-block px-1 align-text-bottom"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><path fill="currentColor" d="M310.6 361.4c12.5 12.5 12.5 32.75 0 45.25C304.4 412.9 296.2 416 288 416s-16.38-3.125-22.62-9.375L160 301.3L54.63 406.6C48.38 412.9 40.19 416 32 416S15.63 412.9 9.375 406.6c-12.5-12.5-12.5-32.75 0-45.25l105.4-105.4L9.375 150.6c-12.5-12.5-12.5-32.75 0-45.25s32.75-12.5 45.25 0L160 210.8l105.4-105.4c12.5-12.5 32.75-12.5 45.25 0s12.5 32.75 0 45.25l-105.4 105.4L310.6 361.4z"/></svg>
</span>
      </button>
    </header>
    <section class="flex-auto overflow-auto px-2">
      <ul id="search-results">
        
      </ul>
    </section>
  </div>
</div>

    </div>
  </body>
</html>
